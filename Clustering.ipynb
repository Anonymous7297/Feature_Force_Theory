{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c492efb0-a710-4422-ac09-7f9b46c91a86",
   "metadata": {},
   "source": [
    "## Text embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41df9472-d1a3-4754-ab70-1b223d958cd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferring text features for index 0\n",
      "[Completed 0/146347]\n",
      "[Completed 102400/146347]\n",
      "Feature shape: (146347, 512)\n",
      "Inferring text features for index 1\n",
      "[Completed 0/146347]\n",
      "[Completed 102400/146347]\n",
      "Feature shape: (146347, 512)\n",
      "Inferring text features for index 2\n",
      "[Completed 0/146347]\n",
      "[Completed 102400/146347]\n",
      "Feature shape: (146347, 512)\n",
      "Inferring text features for index 3\n",
      "[Completed 0/146347]\n",
      "[Completed 102400/146347]\n",
      "Feature shape: (146347, 512)\n",
      "Inferring text features for index 4\n",
      "[Completed 0/146347]\n",
      "[Completed 102400/146347]\n",
      "Feature shape: (146347, 512)\n",
      "Inferring text features for index 5\n",
      "[Completed 0/146347]\n",
      "[Completed 102400/146347]\n",
      "Feature shape: (146347, 512)\n",
      "Inferring text features for index 6\n",
      "[Completed 0/146347]\n",
      "[Completed 102400/146347]\n",
      "Feature shape: (146347, 512)\n"
     ]
    }
   ],
   "source": [
    "import clip\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from models import CLIPModel\n",
    "\n",
    "# a much smaller subset of above prompts\n",
    "# from https://github.com/openai/CLIP/blob/main/notebooks/Prompt_Engineering_for_ImageNet.ipynb\n",
    "SIMPLE_IMAGENET_TEMPLATES = (\n",
    "    # 原始模板\n",
    "    lambda c: f\"itap of a {c}.\",\n",
    "    lambda c: f\"a bad photo of the {c}.\",\n",
    "    lambda c: f\"a origami {c}.\",\n",
    "    lambda c: f\"a photo of the large {c}.\",\n",
    "    lambda c: f\"a {c} in a video game.\",\n",
    "    lambda c: f\"art of the {c}.\",\n",
    "    lambda c: f\"a photo of the small {c}.\",\n",
    "\n",
    "    # 新增模板\n",
    "#     lambda c: f\"a painting of a {c}.\",\n",
    "#     lambda c: f\"a sculpture of the {c}.\",\n",
    "#     lambda c: f\"a digital illustration of the {c}.\",\n",
    "#     lambda c: f\"a {c} in a children's book.\",\n",
    "#     lambda c: f\"a cartoon {c}.\",\n",
    "#     lambda c: f\"a graffiti of the {c}.\",\n",
    ")\n",
    "\n",
    "\n",
    "def get_prompt(words, index, device=\"cuda\"):\n",
    "    prompt = [SIMPLE_IMAGENET_TEMPLATES[index](word) for word in words]\n",
    "    text = clip.tokenize(prompt, truncate=True).to(device)\n",
    "    return text\n",
    "\n",
    "\n",
    "nouns = pd.read_csv(\"./WordNetNouns.csv\").values\n",
    "nouns_num = nouns.shape[0]\n",
    "batch_size = 2048\n",
    "model = CLIPModel(model_name=\"ViT-B/32\").cuda()\n",
    "model.eval()\n",
    "\n",
    "for index in range(len(SIMPLE_IMAGENET_TEMPLATES)):\n",
    "    features = []\n",
    "    print(\"Inferring text features for index\", index)\n",
    "    for i in range(nouns_num // batch_size + 1):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        if end > nouns_num:\n",
    "            end = nouns_num\n",
    "        nouns_batch = nouns[start:end]\n",
    "        with torch.no_grad():\n",
    "            prompt = get_prompt(nouns_batch[:, 0], index)\n",
    "            feature = model.encode_text(prompt)\n",
    "            features.append(feature.cpu().numpy())\n",
    "        if i % 50 == 0:\n",
    "            print(f\"[Completed {i * batch_size}/{nouns_num}]\")\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    print(\"Feature shape:\", features.shape)\n",
    "    np.save(\"./nouns_embedding_prompt_\" + str(index) + \".npy\", features)\n",
    "\n",
    "\n",
    "# Multi Prompts\n",
    "embeddings = np.zeros((nouns_num, 512))\n",
    "for index in range(len(SIMPLE_IMAGENET_TEMPLATES)):\n",
    "    embedding = np.load(\"./nouns_embedding_prompt_\" + str(index) + \".npy\")\n",
    "    embeddings += embedding\n",
    "embeddings = embeddings / len(SIMPLE_IMAGENET_TEMPLATES)\n",
    "np.save(\"./nouns_embedding_ensemble.npy\", embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185ba65b-70c3-4e0b-b082-aaa2f1d2cd1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Image embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "671f17b2-1643-434f-b708-82c6f87f2c98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Inferring image features and labels...\n",
      "[Iter 0/49]\n",
      "[Iter 10/49]\n",
      "[Iter 20/49]\n",
      "[Iter 30/49]\n",
      "[Iter 40/49]\n",
      "Feature shape: (50000, 512) Label shape: (50000,)\n",
      "Inferring test image features and labels...\n",
      "[Iter 0/10]\n",
      "Feature shape: (10000, 512) Label shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import torch\n",
    "import data_utils\n",
    "import numpy as np\n",
    "from models import CLIPModel\n",
    "\n",
    "dataset = \"CIFAR-10\" #　[\"CIFAR-10\", \"CIFAR-20\", \"STL-10\", \"ImageNet-10\", \"ImageNet-Dogs\", \"DTD\", \"UCF101\", \"ImageNet\"]\n",
    "\n",
    "dataloader_train, dataloader_test = data_utils.get_dataloader(\n",
    "    dataset=dataset, batch_size=1024\n",
    ")\n",
    "model = CLIPModel(model_name=\"ViT-B/32\").cuda()\n",
    "model.eval()\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "print(\"Inferring image features and labels...\")\n",
    "for iteration, (x, y) in enumerate(dataloader_train):\n",
    "    x = x.cuda()\n",
    "    with torch.no_grad():\n",
    "        feature = model.encode_image(x)\n",
    "    features.append(feature.cpu().numpy())\n",
    "    labels.append(y.numpy())\n",
    "    if iteration % 10 == 0:\n",
    "        print(f\"[Iter {iteration}/{len(dataloader_train)}]\")\n",
    "features = np.concatenate(features, axis=0)\n",
    "labels = np.concatenate(labels, axis=0)\n",
    "print(\"Feature shape:\", features.shape, \"Label shape:\", labels.shape)\n",
    "\n",
    "features_test = []\n",
    "labels_test = []\n",
    "print(\"Inferring test image features and labels...\")\n",
    "for iteration, (x, y) in enumerate(dataloader_test):\n",
    "    x = x.cuda()\n",
    "    with torch.no_grad():\n",
    "        feature = model.encode_image(x)\n",
    "    features_test.append(feature.cpu().numpy())\n",
    "    labels_test.append(y.numpy())\n",
    "    if iteration % 10 == 0:\n",
    "        print(f\"[Iter {iteration}/{len(dataloader_test)}]\")\n",
    "features_test = np.concatenate(features_test, axis=0)\n",
    "labels_test = np.concatenate(labels_test, axis=0)\n",
    "print(\"Feature shape:\", features_test.shape, \"Label shape:\", labels_test.shape)\n",
    "\n",
    "if dataset == \"CIFAR-20\":\n",
    "    coarse_label = [\n",
    "        [72, 4, 95, 30, 55],\n",
    "        [73, 32, 67, 91, 1],\n",
    "        [92, 70, 82, 54, 62],\n",
    "        [16, 61, 9, 10, 28],\n",
    "        [51, 0, 53, 57, 83],\n",
    "        [40, 39, 22, 87, 86],\n",
    "        [20, 25, 94, 84, 5],\n",
    "        [14, 24, 6, 7, 18],\n",
    "        [43, 97, 42, 3, 88],\n",
    "        [37, 17, 76, 12, 68],\n",
    "        [49, 33, 71, 23, 60],\n",
    "        [15, 21, 19, 31, 38],\n",
    "        [75, 63, 66, 64, 34],\n",
    "        [77, 26, 45, 99, 79],\n",
    "        [11, 2, 35, 46, 98],\n",
    "        [29, 93, 27, 78, 44],\n",
    "        [65, 50, 74, 36, 80],\n",
    "        [56, 52, 47, 59, 96],\n",
    "        [8, 58, 90, 13, 48],\n",
    "        [81, 69, 41, 89, 85],\n",
    "    ]\n",
    "    labels_copy = copy.deepcopy(labels)\n",
    "    labels_test_copy = copy.deepcopy(labels_test)\n",
    "    for i in range(20):\n",
    "        for j in coarse_label[i]:\n",
    "            labels[labels_copy == j] = i\n",
    "            labels_test[labels_test_copy == j] = i\n",
    "\n",
    "np.save(\"./\" + dataset + \"_image_embedding_train.npy\", features)\n",
    "np.save(\"./\" + dataset + \"_image_embedding_test.npy\", features_test)\n",
    "np.savetxt(\"./\" + dataset + \"_labels_train.txt\", labels)\n",
    "np.savetxt(\"./\" + dataset + \"_labels_test.txt\", labels_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f32b87d-a7c4-4a6c-80bb-af54d0fba031",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Semantics Granularity Determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32e21482-6342-4fa2-8594-c3c390c19086",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "def feature_representation(image):\n",
    "    # Convert the image to a feature vector (e.g., intensity, color, texture)\n",
    "    return image.reshape(-1, 3)  # Assuming a color image with RGB channels\n",
    "\n",
    "\n",
    "def calculate_gene_force(image, k=5, w_attr=1.0, w_rep=1.0):\n",
    "    if len(image.shape) > 2:\n",
    "        height, width, _ = image.shape\n",
    "        features = feature_representation(image)\n",
    "    else:\n",
    "        height, width = image.shape\n",
    "        features = image\n",
    "\n",
    "    # Check for NaN values and handle if present\n",
    "    if np.isnan(features).any():\n",
    "        features = np.nan_to_num(features)\n",
    "\n",
    "    # Normalize features\n",
    "    # features = (features - features.mean(axis=0)) / features.std(axis=0)\n",
    "\n",
    "    # K-Nearest Neighbors\n",
    "    knn = NearestNeighbors(n_neighbors=k)\n",
    "    knn.fit(features)\n",
    "    distances, indices = knn.kneighbors(features)\n",
    "\n",
    "    # 用于存储每个点基因力大于等于周围点基因力的个数\n",
    "    greater_count = np.zeros(features.shape[0], dtype=int)\n",
    "    for i in range(features.shape[0]):\n",
    "        current_force = np.zeros(features.shape[1])\n",
    "        for j in range(1, k):\n",
    "            neighbor_index = indices[i, j]\n",
    "            distance = distances[i, j]\n",
    "            if distance == 0:\n",
    "                continue\n",
    "            # 计算吸引力部分\n",
    "            F_attr = (w_attr / distance) * (features[neighbor_index] - features[i])\n",
    "            # 计算排斥力部分\n",
    "            F_rep = (w_rep / (distance ** 2)) * (features[i] - features[neighbor_index])\n",
    "            current_force += F_attr - F_rep\n",
    "\n",
    "        current_force_norm = np.linalg.norm(current_force)  # 计算当前点基因力的模长\n",
    "\n",
    "        # 与周围8个点（这里假设k足够大包含了8个点，可根据实际调整k）比较基因力模长并计数\n",
    "        neighbor_indices = indices[i, 1:9]  # 获取周围8个点的索引，可根据实际调整范围\n",
    "        for neighbor_idx in neighbor_indices:\n",
    "            neighbor_force = np.zeros(features.shape[1])\n",
    "            for m in range(1, k):\n",
    "                nbr_distance = distances[neighbor_idx, m]\n",
    "                if nbr_distance == 0:\n",
    "                    continue\n",
    "                nbr_F_attr = (w_attr / nbr_distance) * (features[indices[neighbor_idx, m]] - features[neighbor_idx])\n",
    "                nbr_F_rep = (w_rep / (nbr_distance ** 2)) * (features[neighbor_idx] - features[indices[neighbor_idx, m]])\n",
    "                neighbor_force += nbr_F_attr - nbr_F_rep\n",
    "            neighbor_force_norm = np.linalg.norm(neighbor_force)  # 计算周围点基因力的模长\n",
    "            if current_force_norm >= neighbor_force_norm:\n",
    "                greater_count[i] += 1\n",
    "\n",
    "    return greater_count\n",
    "\n",
    "\n",
    "def edge_strength(total_force):\n",
    "    return np.linalg.norm(total_force, axis=1)\n",
    "\n",
    "\n",
    "def edge_detection(image, k, w_attr, w_rep, T):\n",
    "    greater_count = calculate_gene_force(image, k, w_attr, w_rep)\n",
    "    return greater_count\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def feature_representation2(image):\n",
    "    # Convert the image to a feature vector (e.g., intensity, color, texture)\n",
    "    return image.reshape(-1, 3)  # Assuming a color image with RGB channels\n",
    "\n",
    "def calculate_gene_force2(image, k=5, w_attr=1.0, w_rep=1.0):\n",
    "    if len(image.shape)>2:\n",
    "        height, width, _ = image.shape\n",
    "        features = feature_representation(image)\n",
    "    else:\n",
    "        height, width= image.shape\n",
    "        features =image\n",
    "    # Check for NaN values and handle if present\n",
    "    if np.isnan(features).any():\n",
    "        features = np.nan_to_num(features)\n",
    "    # Normalize features\n",
    "    #features = (features - features.mean(axis=0)) / features.std(axis=0)\n",
    "    # K-Nearest Neighbors\n",
    "    knn = NearestNeighbors(n_neighbors=k)\n",
    "\n",
    "    knn.fit(features)\n",
    "    distances, indices = knn.kneighbors(features)\n",
    "    # Initialize forces\n",
    "    total_force = np.zeros(features.shape)\n",
    "    for i in range(features.shape[0]):\n",
    "        F_attr = np.zeros(features.shape[1])\n",
    "        F_rep = np.zeros(features.shape[1])\n",
    "        for j in range(1,k):\n",
    "            neighbor_index = indices[i, j]\n",
    "            distance = distances[i, j]\n",
    "            # Attractive force\n",
    "            if distance==0:\n",
    "                continue\n",
    "            F_attr += (w_attr / distance) * (features[neighbor_index] - features[i])\n",
    "            F_rep += (w_rep / (distance ** 2)) * (features[i] - features[neighbor_index])\n",
    "        # Total force\n",
    "        total_force[i] = F_attr - F_rep\n",
    "    return total_force\n",
    "\n",
    "def edge_strength2(total_force):\n",
    "    return np.linalg.norm(total_force, axis=1)\n",
    "\n",
    "def edge_detection(image,k,w_attr,w_rep,T):\n",
    "    total_force = calculate_gene_force2(image,k,w_attr,w_rep)\n",
    "    if len(image.shape)>2:\n",
    "        strength = edge_strength(total_force).reshape(image.shape[:2])\n",
    "    else:\n",
    "        strength = edge_strength2(total_force)\n",
    "    # Thresholding\n",
    "    print(int(T*len(total_force))-1)\n",
    "    threshold=np.sort(strength.flatten())[int(T*len(total_force))-1]\n",
    "    #threshold=np.mean(strength)\n",
    "    #找中心\n",
    "    edges = (strength >= threshold).astype(np.uint8)\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32dd525d-1f6b-4a7a-9198-039976ffb73d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dataset = \"CIFAR-10\"  # [\"CIFAR-10\", \"CIFAR-20\", \"STL-10\", \"ImageNet-10\", \"ImageNet-Dogs\", \"DTD\", \"UCF101\", \"ImageNet\"]\n",
    "images_embedding_train = np.load(\"./\" + dataset + \"_image_embedding_train.npy\")\n",
    "images_embedding_test = np.load(\"./\" + dataset + \"_image_embedding_test.npy\")\n",
    "images_embedding=np.concatenate([images_embedding_train, images_embedding_test], axis=0)\n",
    "k=9\n",
    "w_attr=1\n",
    "w_rep=0.5\n",
    "total_force_values_image = calculate_gene_force2(images_embedding,k,w_attr,w_rep)\n",
    "total_force_strength_image = edge_strength2(total_force_values_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117f1dbf-e4af-4bdd-bd73-62ced58c60af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c319d44e-da1d-4892-83a0-2bc4ef80537c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "均值为: 6.2748080634549055\n",
      "偏度为: 0.028936071175337044\n",
      "标准差为: 0.3604028823929673\n",
      "范围1: 5.914405181061938-6.635210945847873\n",
      "范围2: 5.554002298668971-6.99561382824084\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "\n",
    "# 绘制直方图\n",
    "plt.hist(total_force_strength_image, bins=100, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Total Force Strength')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Total Force Strength')\n",
    "plt.show()\n",
    "\n",
    "# 计算均值\n",
    "mean_value = np.mean(total_force_strength_image)\n",
    "print(f\"均值为: {mean_value}\")\n",
    "skewness = skew(total_force_strength_image)\n",
    "print(f\"偏度为: {skewness}\")\n",
    "# 计算标准差\n",
    "std_value = np.std(total_force_strength_image)\n",
    "print(f\"标准差为: {std_value}\")\n",
    "print(f\"范围1: {mean_value-std_value}-{mean_value+std_value}\")\n",
    "print(f\"范围2: {mean_value-2*std_value}-{mean_value+2*std_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3014db26-4e1d-48d3-a359-9343e1955729",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=0.005\n",
    "mask=(total_force_strength_image>=mean_value-a*std_value)&(total_force_strength_image<=mean_value+a*std_value)\n",
    "cluster_num_best_de=len(total_force_strength_image[mask])\n",
    "cluster_num_best_de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "244d5cd4-03c5-454d-a58e-2e7557ceafcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "\n",
    "# 提取符合条件的数据\n",
    "data_yes_mask = total_force_strength_image[mask]\n",
    "# 提取不符合条件的数据\n",
    "data_no_mask = total_force_strength_image[~mask]\n",
    "\n",
    "# 绘制符合mask条件的直方图，设置颜色等属性\n",
    "\n",
    "\n",
    "# 绘制不符合mask条件的直方图，设置颜色等属性\n",
    "plt.hist(data_no_mask, bins=1000, edgecolor='blue', alpha=0.7, color='blue', label='otherwise')\n",
    "plt.hist(data_yes_mask, bins=1, edgecolor='red', alpha=0.7, color='red', label='mean-theta*std<=Feature-Force<=mean+theta*std')\n",
    "\n",
    "plt.xlabel('Feature-Force Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Feature Force')\n",
    "\n",
    "# 添加图例，方便区分不同颜色代表的部分\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0f59ae-53fe-474a-a1eb-a48592350830",
   "metadata": {},
   "source": [
    "## Filter Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "383c7dbd-b291-4426-82f4-1cab2694fb6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257\n",
      "1087 nouns selected.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import faiss\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def kmeans(X, cluster_num):\n",
    "    print(\"Perform K-means clustering...\")\n",
    "    d = X.shape[1]\n",
    "    X = X.astype(np.float32)\n",
    "    kmeans = faiss.Kmeans(d, cluster_num, gpu=True, spherical=True, niter=300, nredo=10)\n",
    "    kmeans.train(X)\n",
    "    D, I = kmeans.index.search(X, 1)\n",
    "    I = I.reshape(-1)\n",
    "    print(\"K-means clustering done.\")\n",
    "    return I\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset = \"CIFAR-10\"  # [\"CIFAR-10\", \"CIFAR-20\", \"STL-10\", \"ImageNet-10\", \"ImageNet-Dogs\", \"DTD\", \"UCF101\", \"ImageNet\"]\n",
    "    #cluster_num = 279  # [167, 167, 17, 43, 65, 141, 303, 4271]\n",
    "    topK = 5\n",
    "\n",
    "    nouns_embedding = np.load(\"./nouns_embedding_ensemble.npy\")\n",
    "    nouns_embedding = nouns_embedding / np.linalg.norm(\n",
    "        nouns_embedding, axis=1, keepdims=True\n",
    "    )\n",
    "    #images_embedding = np.load(\"./\" + dataset + \"_image_embedding_test.npy\")\n",
    "\n",
    "\n",
    "    images_embedding = images_embedding / np.linalg.norm(\n",
    "        images_embedding, axis=1, keepdims=True\n",
    "    )\n",
    "\n",
    "    nouns_embedding = torch.from_numpy(nouns_embedding).cuda().half()\n",
    "    nouns_num = nouns_embedding.shape[0]\n",
    "\n",
    "    images_embedding = torch.from_numpy(images_embedding).cuda().half()\n",
    "    image_num = images_embedding.shape[0]\n",
    "\n",
    "    \n",
    "    \n",
    "    cluster_num_best=cluster_num_best_de\n",
    "    print(cluster_num_best)\n",
    "    try:\n",
    "        preds = np.load(\n",
    "            \"./\" + dataset + \"_image_\" + str(cluster_num_best) + \"cluster.npy\"\n",
    "        )\n",
    "    except:\n",
    "        preds = kmeans(images_embedding.cpu().numpy(), cluster_num_best)\n",
    "        np.save(\n",
    "            \"./\" + dataset + \"_image_\" + str(cluster_num_best) + \"cluster.npy\", preds\n",
    "        )\n",
    "        print(\"Please rerun the script.\")\n",
    "        exit()\n",
    "\n",
    "    image_centers = torch.zeros((cluster_num_best, 512), dtype=torch.float16).cuda()\n",
    "    for k in range(cluster_num_best):\n",
    "        image_centers[k] = images_embedding[preds == k].mean(dim=0)\n",
    "    image_centers = F.normalize(image_centers, dim=1)\n",
    "\n",
    "    similarity = torch.matmul(image_centers, nouns_embedding.T)\n",
    "    softmax_nouns = torch.softmax(similarity, dim=0).cpu().float()\n",
    "    class_pred = torch.argmax(softmax_nouns, dim=0).long()\n",
    "\n",
    "    selected_idx = torch.zeros_like(class_pred, dtype=torch.bool)\n",
    "    for k in range(cluster_num_best):\n",
    "        if (class_pred == k).sum() == 0:\n",
    "            continue\n",
    "        class_index = torch.where(class_pred == k)[0]\n",
    "        softmax_class = softmax_nouns[:, class_index]\n",
    "        confidence = softmax_class.max(dim=0)[0]\n",
    "        rank = torch.argsort(confidence, descending=True)\n",
    "        selected_idx[class_index[rank[:topK]]] = True\n",
    "    selected_idx = selected_idx.cpu().numpy()\n",
    "\n",
    "    print(selected_idx.sum(), \"nouns selected.\")\n",
    "    nouns_embedding_selected = nouns_embedding[selected_idx]\n",
    "\n",
    "    np.save(\n",
    "        \"./\" + dataset + \"_filtered_nouns_embedding.npy\",\n",
    "        nouns_embedding_selected.cpu().numpy(),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136b4bcd-cfbd-46fa-b498-e60ef1ee2b20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59a4a5df-c25f-47a6-8860-11edbc0b5370",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Concatenate Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "855b383d-f5d3-4988-9d22-24980dec5f46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform K-means clustering...\n",
      "K-means clustering done.\n",
      "[Clustering Result]: ACC = 90.67, NMI = 81.54, ARI = 80.77\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import faiss\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from eval_utils import cluster_metric\n",
    "\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "def kmeans(X, cluster_num):\n",
    "    print(\"Perform K-means clustering...\")\n",
    "    d = X.shape[1]\n",
    "    kmeans = faiss.Kmeans(d, cluster_num, gpu=True, spherical=True, niter=300, nredo=20)\n",
    "    X = X.astype(np.float32)\n",
    "    kmeans.train(X)\n",
    "    D, I = kmeans.index.search(X, 1)\n",
    "    I = I.reshape(-1)\n",
    "    print(\"K-means clustering done.\")\n",
    "    return I\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset = \"CIFAR-10\"  # 　[\"CIFAR-10\", \"CIFAR-20\", \"STL-10\", \"ImageNet-10\", \"ImageNet-Dogs\", \"DTD\", \"UCF101\", \"ImageNet\"]\n",
    "    tau = 0.005\n",
    "    if dataset == \"CIFAR-10\" or dataset == \"STL-10\" or dataset == \"ImageNet-10\":\n",
    "        cluster_num = 10\n",
    "    elif dataset == \"CIFAR-20\":\n",
    "        cluster_num = 20\n",
    "    elif dataset == \"ImageNet-Dogs\":\n",
    "        cluster_num = 15\n",
    "    elif dataset == \"DTD\":\n",
    "        cluster_num = 47\n",
    "    elif dataset == \"UCF101\":\n",
    "        cluster_num = 101\n",
    "    elif dataset == \"ImageNet\":\n",
    "        cluster_num = 1000\n",
    "    elif dataset == \"MNIST\":\n",
    "        cluster_num = 10\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    images_embedding_test = np.load(\"./\" + dataset + \"_image_embedding_test.npy\")\n",
    "    images_embedding_test = images_embedding_test / np.linalg.norm(\n",
    "        images_embedding_test, axis=1, keepdims=True\n",
    "    )\n",
    "    labels_test = np.loadtxt(\"./\" + dataset + \"_labels_test.txt\")\n",
    "\n",
    "    nouns_embedding = np.load(\"./\" + dataset + \"_filtered_nouns_embedding.npy\")\n",
    "    nouns_embedding = nouns_embedding / np.linalg.norm(\n",
    "        nouns_embedding, axis=1, keepdims=True\n",
    "    )\n",
    "\n",
    "    nouns_embedding = torch.from_numpy(nouns_embedding).cuda().half()\n",
    "    nouns_num = nouns_embedding.shape[0]\n",
    "    images_embedding_test = torch.from_numpy(images_embedding_test).cuda().half()\n",
    "    image_num_test = images_embedding_test.shape[0]\n",
    "\n",
    "    retrieval_embeddings = []\n",
    "    batch_size = 1024\n",
    "    for i in range(image_num_test // batch_size + 1):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        if end > image_num_test:\n",
    "            end = image_num_test\n",
    "            images_batch = images_embedding_test[start:end]\n",
    "        similarity = torch.matmul(images_embedding_test[start:end], nouns_embedding.T)\n",
    "        similarity = torch.softmax(similarity / tau, dim=1)\n",
    "        retrieval_embedding = (similarity @ nouns_embedding).cpu()\n",
    "        retrieval_embeddings.append(retrieval_embedding)\n",
    "    retrieval_embedding = torch.cat(retrieval_embeddings, dim=0).cuda().half()\n",
    "    retrieval_embedding = F.normalize(retrieval_embedding, dim=1).cpu().numpy()\n",
    "    images_embedding_test = images_embedding_test.cpu().numpy()\n",
    "\n",
    "    concat_embedding_test = np.concatenate([images_embedding_test, retrieval_embedding], axis=1)\n",
    "    preds_ = kmeans(concat_embedding_test, cluster_num)\n",
    "    cluster_metric(labels_test, preds_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "311513c5-3af1-4b66-8405-bb8678c659b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform K-means clustering...\n",
      "K-means clustering done.\n",
      "[Clustering Result]: ACC = 90.64, NMI = 81.40, ARI = 80.70\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import faiss\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from eval_utils import cluster_metric\n",
    "\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "def kmeans(X, cluster_num):\n",
    "    print(\"Perform K-means clustering...\")\n",
    "    d = X.shape[1]\n",
    "    kmeans = faiss.Kmeans(d, cluster_num, gpu=True, spherical=True, niter=300, nredo=20)\n",
    "    X = X.astype(np.float32)\n",
    "    kmeans.train(X)\n",
    "    D, I = kmeans.index.search(X, 1)\n",
    "    I = I.reshape(-1)\n",
    "    print(\"K-means clustering done.\")\n",
    "    return I\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset = \"CIFAR-10\"  # 　[\"CIFAR-10\", \"CIFAR-20\", \"STL-10\", \"ImageNet-10\", \"ImageNet-Dogs\", \"DTD\", \"UCF101\", \"ImageNet\"]\n",
    "    tau = 0.005\n",
    "    if dataset == \"CIFAR-10\" or dataset == \"STL-10\" or dataset == \"ImageNet-10\":\n",
    "        cluster_num = 10\n",
    "    elif dataset == \"CIFAR-20\":\n",
    "        cluster_num = 20\n",
    "    elif dataset == \"ImageNet-Dogs\":\n",
    "        cluster_num = 15\n",
    "    elif dataset == \"DTD\":\n",
    "        cluster_num = 47\n",
    "    elif dataset == \"UCF101\":\n",
    "        cluster_num = 101\n",
    "    elif dataset == \"ImageNet\":\n",
    "        cluster_num = 1000\n",
    "    elif dataset == \"MNIST\":\n",
    "        cluster_num = 10\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    images_embedding_train = np.load(\"./\" + dataset + \"_image_embedding_train.npy\")\n",
    "    images_embedding_train = images_embedding_train / np.linalg.norm(\n",
    "        images_embedding_train, axis=1, keepdims=True\n",
    "    )\n",
    "    labels_train = np.loadtxt(\"./\" + dataset + \"_labels_train.txt\")\n",
    "\n",
    "    nouns_embedding = np.load(\"./\" + dataset + \"_filtered_nouns_embedding.npy\")\n",
    "    nouns_embedding = nouns_embedding / np.linalg.norm(\n",
    "        nouns_embedding, axis=1, keepdims=True\n",
    "    )\n",
    "\n",
    "    nouns_embedding = torch.from_numpy(nouns_embedding).cuda().half()\n",
    "    nouns_num = nouns_embedding.shape[0]\n",
    "    images_embedding_train = torch.from_numpy(images_embedding_train).cuda().half()\n",
    "    image_num_train = images_embedding_train.shape[0]\n",
    "\n",
    "    retrieval_embeddings = []\n",
    "    batch_size = 1024\n",
    "    for i in range(image_num_train // batch_size + 1):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        if end > image_num_train:\n",
    "            end = image_num_train\n",
    "            images_batch = images_embedding_train[start:end]\n",
    "        similarity = torch.matmul(images_embedding_train[start:end], nouns_embedding.T)\n",
    "        similarity = torch.softmax(similarity / tau, dim=1)\n",
    "        retrieval_embedding = (similarity @ nouns_embedding).cpu()\n",
    "        retrieval_embeddings.append(retrieval_embedding)\n",
    "    retrieval_embedding = torch.cat(retrieval_embeddings, dim=0).cuda().half()\n",
    "    retrieval_embedding = F.normalize(retrieval_embedding, dim=1).cpu().numpy()\n",
    "    images_embedding_train = images_embedding_train.cpu().numpy()\n",
    "\n",
    "    concat_embedding_train = np.concatenate([images_embedding_train, retrieval_embedding], axis=1)\n",
    "    preds_train = kmeans(concat_embedding_train, cluster_num)\n",
    "    cluster_metric(labels_train, preds_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2136207-9a03-480c-9843-70a14ad9baba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "concat_embedding=np.concatenate([concat_embedding_train, concat_embedding_test], axis=0)\n",
    "labels=np.concatenate([labels_train, labels_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c945d8e-27b0-4b8e-aea5-a95c123799c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1024)\n",
      "Perform K-means clustering...\n",
      "K-means clustering done.\n",
      "[Clustering Result]: ACC = 76.44, NMI = 76.82, ARI = 69.19\n"
     ]
    }
   ],
   "source": [
    "print(concat_embedding.shape)\n",
    "preds = kmeans(concat_embedding, cluster_num)\n",
    "cluster_metric(labels, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64bed89-0460-43de-a351-5a436e26a34c",
   "metadata": {},
   "source": [
    "## Feature Force Computation & Pseudo label Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26bb9392-7d32-4faa-a4b2-d2850cd1582f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "def feature_representation(image):\n",
    "    # Convert the image to a feature vector (e.g., intensity, color, texture)\n",
    "    return image.reshape(-1, 3)  # Assuming a color image with RGB channels\n",
    "\n",
    "\n",
    "def calculate_gene_force(image, k=5, w_attr=1.0, w_rep=1.0):\n",
    "    if len(image.shape) > 2:\n",
    "        height, width, _ = image.shape\n",
    "        features = feature_representation(image)\n",
    "    else:\n",
    "        height, width = image.shape\n",
    "        features = image\n",
    "\n",
    "    # Check for NaN values and handle if present\n",
    "    if np.isnan(features).any():\n",
    "        features = np.nan_to_num(features)\n",
    "\n",
    "    # Normalize features\n",
    "    # features = (features - features.mean(axis=0)) / features.std(axis=0)\n",
    "\n",
    "    # K-Nearest Neighbors\n",
    "    knn = NearestNeighbors(n_neighbors=k)\n",
    "    knn.fit(features)\n",
    "    distances, indices = knn.kneighbors(features)\n",
    "\n",
    "    # 用于存储每个点基因力大于等于周围点基因力的个数\n",
    "    greater_count = np.zeros(features.shape[0], dtype=int)\n",
    "    for i in range(features.shape[0]):\n",
    "        current_force = np.zeros(features.shape[1])\n",
    "        for j in range(1, k):\n",
    "            neighbor_index = indices[i, j]\n",
    "            distance = distances[i, j]\n",
    "            if distance == 0:\n",
    "                continue\n",
    "            # 计算吸引力部分\n",
    "            F_attr = (w_attr / distance) * (features[neighbor_index] - features[i])\n",
    "            # 计算排斥力部分\n",
    "            F_rep = (w_rep / (distance ** 2)) * (features[i] - features[neighbor_index])\n",
    "            current_force += F_attr - F_rep\n",
    "\n",
    "        current_force_norm = np.linalg.norm(current_force)  # 计算当前点基因力的模长\n",
    "\n",
    "        # 与周围8个点（这里假设k足够大包含了8个点，可根据实际调整k）比较基因力模长并计数\n",
    "        neighbor_indices = indices[i, 1:9]  # 获取周围8个点的索引，可根据实际调整范围\n",
    "        for neighbor_idx in neighbor_indices:\n",
    "            neighbor_force = np.zeros(features.shape[1])\n",
    "            for m in range(1, k):\n",
    "                nbr_distance = distances[neighbor_idx, m]\n",
    "                if nbr_distance == 0:\n",
    "                    continue\n",
    "                nbr_F_attr = (w_attr / nbr_distance) * (features[indices[neighbor_idx, m]] - features[neighbor_idx])\n",
    "                nbr_F_rep = (w_rep / (nbr_distance ** 2)) * (features[neighbor_idx] - features[indices[neighbor_idx, m]])\n",
    "                neighbor_force += nbr_F_attr - nbr_F_rep\n",
    "            neighbor_force_norm = np.linalg.norm(neighbor_force)  # 计算周围点基因力的模长\n",
    "            if current_force_norm >= neighbor_force_norm:\n",
    "                greater_count[i] += 1\n",
    "\n",
    "    return greater_count\n",
    "\n",
    "\n",
    "def edge_strength(total_force):\n",
    "    return np.linalg.norm(total_force, axis=1)\n",
    "\n",
    "\n",
    "def edge_detection(image, k, w_attr, w_rep, T):\n",
    "    greater_count = calculate_gene_force(image, k, w_attr, w_rep)\n",
    "    return greater_count\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def feature_representation2(image):\n",
    "    # Convert the image to a feature vector (e.g., intensity, color, texture)\n",
    "    return image.reshape(-1, 3)  # Assuming a color image with RGB channels\n",
    "\n",
    "def calculate_gene_force2(image, k=5, w_attr=1.0, w_rep=1.0):\n",
    "    if len(image.shape)>2:\n",
    "        height, width, _ = image.shape\n",
    "        features = feature_representation(image)\n",
    "    else:\n",
    "        height, width= image.shape\n",
    "        features =image\n",
    "    # Check for NaN values and handle if present\n",
    "    if np.isnan(features).any():\n",
    "        features = np.nan_to_num(features)\n",
    "    # Normalize features\n",
    "    #features = (features - features.mean(axis=0)) / features.std(axis=0)\n",
    "    # K-Nearest Neighbors\n",
    "    knn = NearestNeighbors(n_neighbors=k)\n",
    "\n",
    "    knn.fit(features)\n",
    "    distances, indices = knn.kneighbors(features)\n",
    "    # Initialize forces\n",
    "    total_force = np.zeros(features.shape)\n",
    "    for i in range(features.shape[0]):\n",
    "        F_attr = np.zeros(features.shape[1])\n",
    "        F_rep = np.zeros(features.shape[1])\n",
    "        for j in range(1,k):\n",
    "            neighbor_index = indices[i, j]\n",
    "            distance = distances[i, j]\n",
    "            # Attractive force\n",
    "            if distance==0:\n",
    "                continue\n",
    "            F_attr += (w_attr / distance) * (features[neighbor_index] - features[i])\n",
    "            F_rep += (w_rep / (distance ** 2)) * (features[i] - features[neighbor_index])\n",
    "        # Total force\n",
    "        total_force[i] = F_attr - F_rep\n",
    "    return total_force\n",
    "\n",
    "def edge_strength2(total_force):\n",
    "    return np.linalg.norm(total_force, axis=1)\n",
    "\n",
    "def edge_detection(image,k,w_attr,w_rep,T):\n",
    "    total_force = calculate_gene_force2(image,k,w_attr,w_rep)\n",
    "    if len(image.shape)>2:\n",
    "        strength = edge_strength(total_force).reshape(image.shape[:2])\n",
    "    else:\n",
    "        strength = edge_strength2(total_force)\n",
    "    # Thresholding\n",
    "    print(int(T*len(total_force))-1)\n",
    "    threshold=np.sort(strength.flatten())[int(T*len(total_force))-1]\n",
    "    #threshold=np.mean(strength)\n",
    "    #找中心\n",
    "    edges = (strength >= threshold).astype(np.uint8)\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1894e95-a75b-4ea1-ae62-05d6857c2a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=9\n",
    "w_attr=1\n",
    "w_rep=0.5\n",
    "total_force_values = calculate_gene_force2(concat_embedding,k,w_attr,w_rep)\n",
    "total_force_strength = edge_strength2(total_force_values)\n",
    "#total_force_strength = np.load(\"./\" + dataset + \"_total_force_strength.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51166763-c1bc-410e-936b-a57031ac8b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./\" + dataset + \"_total_force_strength.npy\", total_force_strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd8f99ef-a90f-49c9-bd35-799d3c050ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_strength_based_on_threshold(strength, global_threshold):\n",
    "    adjusted_strength = np.copy(strength)\n",
    "    for i in range(len(strength)):\n",
    "        if strength[i] < global_threshold:\n",
    "            adjusted_strength[i] = (global_threshold-strength[i])\n",
    "        elif strength[i] > global_threshold:\n",
    "            adjusted_strength[i] = adjusted_strength[i]-global_threshold\n",
    "    return adjusted_strength\n",
    "total_force_strength=adjust_strength_based_on_threshold(total_force_strength, np.percentile(total_force_strength, 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6602a44f-ac81-428f-9e1e-98c373308082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "均值为: 1.2486282407538882\n",
      "偏度为: 0.8876545993983279\n",
      "标准差为: 0.8510699952568098\n",
      "范围1: 0.3975582454970784-2.099698236010698\n",
      "范围2: -0.4535117497597314-2.950768231267508\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "\n",
    "plt.hist(total_force_strength, bins=100, edgecolor='black', alpha=0.7)\n",
    "\n",
    "plt.xlabel('Total Force Strength')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Total Force Strength')\n",
    "plt.show()\n",
    "\n",
    "# 计算均值\n",
    "mean_value = np.mean(total_force_strength)\n",
    "print(f\"均值为: {mean_value}\")\n",
    "skewness = skew(total_force_strength)\n",
    "print(f\"偏度为: {skewness}\")\n",
    "# 计算标准差\n",
    "std_value = np.std(total_force_strength)\n",
    "print(f\"标准差为: {std_value}\")\n",
    "print(f\"范围1: {mean_value-std_value}-{mean_value+std_value}\")\n",
    "print(f\"范围2: {mean_value-2*std_value}-{mean_value+2*std_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "119fb35f-3cc7-4982-805c-5171822c7e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## sita=2\n",
    "\n",
    "mask=(total_force_strength <=1.8)\n",
    "#(total_force_strength <=mean_value+sita*std_value)&(total_force_strength >=mean_value-sita*std_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d7ce8af-597a-467a-accd-9a05a24677a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "\n",
    "# 提取符合条件的数据\n",
    "data_yes_mask = total_force_strength[mask]\n",
    "# 提取不符合条件的数据\n",
    "data_no_mask = total_force_strength[~mask]\n",
    "\n",
    "# 绘制符合mask条件的直方图，设置颜色等属性\n",
    "plt.hist(data_yes_mask, bins=300, edgecolor='red', alpha=0.7, color='red', label='Edge Strength<= 1.8')\n",
    "\n",
    "# 绘制不符合mask条件的直方图，设置颜色等属性\n",
    "plt.hist(data_no_mask, bins=1000, edgecolor='blue', alpha=0.7, color='blue', label='Edge Strength> 1.8')\n",
    "\n",
    "plt.xlabel('Edge Strength')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Edge Strength')\n",
    "\n",
    "# 添加图例，方便区分不同颜色代表的部分\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0beeded7-6c50-4bd2-ba2b-56c1b7ae0742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7520333333333333"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_yes_mask)/len(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae03c997-1773-475f-85f6-cd4dc8fc563f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform K-means clustering...\n",
      "K-means clustering done.\n",
      "[Clustering Result]: ACC = 94.16, NMI = 87.49, ARI = 87.86\n"
     ]
    }
   ],
   "source": [
    "def kmeans(X, cluster_num):\n",
    "    print(\"Perform K-means clustering...\")\n",
    "    d = X.shape[1]\n",
    "    kmeans = faiss.Kmeans(d, cluster_num, gpu=True, spherical=True, niter=300, nredo=20)\n",
    "    X = X.astype(np.float32)\n",
    "    kmeans.train(X)\n",
    "    D, I = kmeans.index.search(X, 1)\n",
    "    I = I.reshape(-1)\n",
    "    print(\"K-means clustering done.\")\n",
    "    return I\n",
    "preds = kmeans(concat_embedding[mask], cluster_num)\n",
    "cluster_metric(labels[mask], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f29e6e7f-e828-47a6-81b9-1963dfaf40ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7520333333333333"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels[mask])/len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ddf903-caeb-42b0-ab63-e8ade1313edf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PSEUDO TRAIN STARTING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19729ef-d6b6-49f1-a8e3-684f7218a099",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Stage 1: ResNet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba5c85f4-b5a6-45fa-9f02-086e8fdc9c2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9415806036966446"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "此部分代码块仅仅是为了方便观察训练过程而进行的真实标签与聚类标签的对齐，对聚类结果没有任何影响\n",
    "也就是说，可以不运行此代码块\n",
    "另外后续的Stage没有进行映射，可以看出仅仅影响了我们对直观准确率的观察，最终聚类结果没有影响\n",
    "'''\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from munkres import Munkres\n",
    "def calculate_cost_matrix(C, n_clusters):\n",
    "    cost_matrix = np.zeros((n_clusters, n_clusters))\n",
    "    # cost_matrix[i,j] will be the cost of assigning cluster i to label j\n",
    "    for j in range(n_clusters):\n",
    "        s = np.sum(C[:, j])  # number of examples in cluster i\n",
    "        for i in range(n_clusters):\n",
    "            t = C[i, j]\n",
    "            cost_matrix[j, i] = s - t\n",
    "    return cost_matrix\n",
    "\n",
    "\n",
    "def get_cluster_labels_from_indices(indices):\n",
    "    n_clusters = len(indices)\n",
    "    cluster_labels = np.zeros(n_clusters)\n",
    "    for i in range(n_clusters):\n",
    "        cluster_labels[i] = indices[i][1]\n",
    "    return cluster_labels\n",
    "\n",
    "\n",
    "def get_y_preds(y_true, cluster_assignments, n_clusters):\n",
    "    \"\"\"\n",
    "    Computes the predicted labels, where label assignments now\n",
    "    correspond to the actual labels in y_true (as estimated by Munkres)\n",
    "    cluster_assignments:    array of labels, outputted by kmeans\n",
    "    y_true:                 true labels\n",
    "    n_clusters:             number of clusters in the dataset\n",
    "    returns:    a tuple containing the accuracy and confusion matrix,\n",
    "                in that order\n",
    "    \"\"\"\n",
    "    confusion_matrix = metrics.confusion_matrix(\n",
    "        y_true, cluster_assignments, labels=None\n",
    "    )\n",
    "    # compute accuracy based on optimal 1:1 assignment of clusters to labels\n",
    "    cost_matrix = calculate_cost_matrix(confusion_matrix, n_clusters)\n",
    "    indices = Munkres().compute(cost_matrix)\n",
    "    kmeans_to_true_cluster_labels = get_cluster_labels_from_indices(indices)\n",
    "\n",
    "    if np.min(cluster_assignments) != 0:\n",
    "        cluster_assignments = cluster_assignments - np.min(cluster_assignments)\n",
    "    y_pred = kmeans_to_true_cluster_labels[cluster_assignments]\n",
    "    return y_pred\n",
    "#labels = np.loadtxt(\"./\" + dataset + \"_labels_test.txt\")\n",
    "train_labels = get_y_preds(labels[mask], preds, 10)\n",
    "metrics.accuracy_score(train_labels,labels[mask])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a818e841-153b-4a76-8378-d073c5e0737e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "训练数据加载器train_loader已创建成功！\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "# 定义数据变换（这里假设myTransforms已经在别处定义好了，你可以根据实际需求调整变换方式）\n",
    "\n",
    "pseudo_labels = torch.tensor(train_labels)  # 假设是10分类任务，生成对应长度的伪标签\n",
    "\n",
    "# 之前定义的原始数据预处理操作（保持不变）\n",
    "myTransforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# 加载STL10训练数据集\n",
    "dataset1 =  torchvision.datasets.CIFAR10(root='./', train=True, download=True, transform=myTransforms)\n",
    "dataset2 =  torchvision.datasets.CIFAR10(root='./', train=False, download=True, transform=myTransforms)\n",
    "train_dataset = ConcatDataset([dataset1, dataset2])\n",
    "mask_list = [mask]\n",
    "\n",
    "# 用于存储从train_dataset中根据掩码提取出来的数据和对应的伪标签\n",
    "subset_images = []\n",
    "\n",
    "# 依次根据掩码从train_dataset中提取数据并合并\n",
    "for mask in mask_list:\n",
    "    # 将掩码转换为布尔索引（如果不是布尔类型的话，需要进行相应转换）\n",
    "    if not isinstance(mask, np.ndarray):\n",
    "        mask = np.array(mask).astype(bool)\n",
    "    # 根据布尔索引从train_dataset中获取图像数据\n",
    "    subset_images.extend([train_dataset[i][0] for i in np.where(mask)[0]])\n",
    "    # 这里假设伪标签的获取方式是和图像数据对应的，你可以根据实际情况调整获取逻辑\n",
    "\n",
    "# 将合并后的数据和标签转换为Tensor类型\n",
    "subset_images = torch.stack(subset_images)\n",
    "\n",
    "# 创建自定义的Dataset，将合并后的数据和标签组合在一起\n",
    "combined_dataset = TensorDataset(subset_images, pseudo_labels)\n",
    "\n",
    "# 创建DataLoader，设置合适的参数，比如批量大小（batch_size）、是否打乱数据（shuffle）等\n",
    "batch_size = 32  # 可根据实际需求调整批量大小\n",
    "train_loader = DataLoader(combined_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "print(\"训练数据加载器train_loader已创建成功！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b2db2f0-3796-4e5f-a1fc-8a1bbbe013c3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-16 15:42:29.078962: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-16 15:42:29.144361: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-16 15:42:30.131223: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "[iteration -   0] training loss: 0.002\n",
      "\n",
      "[iteration - 1000] training loss: 0.472\n",
      "\n",
      "[Clustering Result]: ACC = 93.05, NMI = 85.84, ARI = 85.46\n",
      "Testing Accuracy : 93.050 %\n",
      "[iteration - 1411] training loss: 0.000\n",
      "\n",
      "[iteration - 2411] training loss: 0.294\n",
      "\n",
      "[Clustering Result]: ACC = 91.70, NMI = 83.18, ARI = 82.59\n",
      "Testing Accuracy : 91.700 %\n",
      "[iteration - 2822] training loss: 0.000\n",
      "\n",
      "[iteration - 3822] training loss: 0.220\n",
      "\n",
      "[Clustering Result]: ACC = 91.52, NMI = 84.15, ARI = 82.27\n",
      "Testing Accuracy : 91.520 %\n",
      "[iteration - 4233] training loss: 0.000\n",
      "\n",
      "[iteration - 5233] training loss: 0.157\n",
      "\n",
      "[Clustering Result]: ACC = 92.44, NMI = 85.00, ARI = 84.25\n",
      "Testing Accuracy : 92.440 %\n",
      "[iteration - 5644] training loss: 0.000\n",
      "\n",
      "[iteration - 6644] training loss: 0.116\n",
      "\n",
      "[Clustering Result]: ACC = 90.08, NMI = 82.16, ARI = 79.12\n",
      "Testing Accuracy : 90.080 %\n",
      "[iteration - 7055] training loss: 0.000\n",
      "\n",
      "[iteration - 8055] training loss: 0.083\n",
      "\n",
      "[Clustering Result]: ACC = 90.30, NMI = 82.39, ARI = 80.37\n",
      "Testing Accuracy : 90.300 %\n",
      "[iteration - 8466] training loss: 0.000\n",
      "\n",
      "[iteration - 9466] training loss: 0.086\n",
      "\n",
      "[Clustering Result]: ACC = 92.10, NMI = 83.84, ARI = 83.49\n",
      "Testing Accuracy : 92.100 %\n",
      "[iteration - 9877] training loss: 0.000\n",
      "\n",
      "[iteration - 10877] training loss: 0.058\n",
      "\n",
      "[Clustering Result]: ACC = 91.40, NMI = 82.36, ARI = 82.28\n",
      "Testing Accuracy : 91.400 %\n",
      "[iteration - 11288] training loss: 0.000\n",
      "\n",
      "[iteration - 12288] training loss: 0.041\n",
      "\n",
      "[Clustering Result]: ACC = 92.27, NMI = 83.95, ARI = 83.87\n",
      "Testing Accuracy : 92.270 %\n",
      "[iteration - 12699] training loss: 0.000\n",
      "\n",
      "[iteration - 13699] training loss: 0.044\n",
      "\n",
      "[Clustering Result]: ACC = 90.72, NMI = 82.05, ARI = 80.72\n",
      "Testing Accuracy : 90.720 %\n",
      "[iteration - 14110] training loss: 0.000\n",
      "\n",
      "[iteration - 15110] training loss: 0.035\n",
      "\n",
      "[Clustering Result]: ACC = 92.00, NMI = 83.58, ARI = 83.29\n",
      "Testing Accuracy : 92.000 %\n",
      "[iteration - 15521] training loss: 0.000\n",
      "\n",
      "[iteration - 16521] training loss: 0.024\n",
      "\n",
      "[Clustering Result]: ACC = 91.94, NMI = 83.61, ARI = 83.09\n",
      "Testing Accuracy : 91.940 %\n",
      "[iteration - 16932] training loss: 0.000\n",
      "\n",
      "[iteration - 17932] training loss: 0.023\n",
      "\n",
      "[Clustering Result]: ACC = 91.27, NMI = 82.63, ARI = 81.84\n",
      "Testing Accuracy : 91.270 %\n",
      "[iteration - 18343] training loss: 0.000\n",
      "\n",
      "[iteration - 19343] training loss: 0.023\n",
      "\n",
      "[Clustering Result]: ACC = 92.43, NMI = 84.16, ARI = 84.14\n",
      "Testing Accuracy : 92.430 %\n",
      "[iteration - 19754] training loss: 0.000\n",
      "\n",
      "[iteration - 20754] training loss: 0.026\n",
      "\n",
      "[Clustering Result]: ACC = 92.56, NMI = 84.53, ARI = 84.49\n",
      "Testing Accuracy : 92.560 %\n",
      "[iteration - 21165] training loss: 0.000\n",
      "\n",
      "[iteration - 22165] training loss: 0.019\n",
      "\n",
      "[Clustering Result]: ACC = 92.38, NMI = 84.48, ARI = 84.17\n",
      "Testing Accuracy : 92.380 %\n",
      "[iteration - 22576] training loss: 0.000\n",
      "\n",
      "[iteration - 23576] training loss: 0.016\n",
      "\n",
      "[Clustering Result]: ACC = 92.14, NMI = 84.09, ARI = 83.61\n",
      "Testing Accuracy : 92.140 %\n",
      "[iteration - 23987] training loss: 0.000\n",
      "\n",
      "[iteration - 24987] training loss: 0.017\n",
      "\n",
      "[Clustering Result]: ACC = 93.16, NMI = 85.57, ARI = 85.67\n",
      "Testing Accuracy : 93.160 %\n",
      "[iteration - 25398] training loss: 0.000\n",
      "\n",
      "[iteration - 26398] training loss: 0.012\n",
      "\n",
      "[Clustering Result]: ACC = 92.81, NMI = 84.98, ARI = 84.96\n",
      "Testing Accuracy : 92.810 %\n",
      "[iteration - 26809] training loss: 0.000\n",
      "\n",
      "[iteration - 27809] training loss: 0.009\n",
      "\n",
      "[Clustering Result]: ACC = 92.69, NMI = 84.70, ARI = 84.71\n",
      "Testing Accuracy : 92.690 %\n",
      "[iteration - 28220] training loss: 0.000\n",
      "\n",
      "[iteration - 29220] training loss: 0.012\n",
      "\n",
      "[Clustering Result]: ACC = 92.06, NMI = 83.86, ARI = 83.51\n",
      "Testing Accuracy : 92.060 %\n",
      "[iteration - 29631] training loss: 0.000\n",
      "\n",
      "[iteration - 30631] training loss: 0.009\n",
      "\n",
      "[Clustering Result]: ACC = 92.00, NMI = 83.78, ARI = 83.33\n",
      "Testing Accuracy : 92.000 %\n",
      "[iteration - 31042] training loss: 0.000\n",
      "\n",
      "[iteration - 32042] training loss: 0.016\n",
      "\n",
      "[Clustering Result]: ACC = 93.04, NMI = 85.41, ARI = 85.41\n",
      "Testing Accuracy : 93.040 %\n",
      "[iteration - 32453] training loss: 0.000\n",
      "\n",
      "[iteration - 33453] training loss: 0.013\n",
      "\n",
      "[Clustering Result]: ACC = 93.32, NMI = 85.79, ARI = 85.96\n",
      "Testing Accuracy : 93.320 %\n",
      "[iteration - 33864] training loss: 0.000\n",
      "\n",
      "[iteration - 34864] training loss: 0.003\n",
      "\n",
      "[Clustering Result]: ACC = 92.19, NMI = 84.16, ARI = 83.73\n",
      "Testing Accuracy : 92.190 %\n",
      "[iteration - 35275] training loss: 0.000\n",
      "\n",
      "[iteration - 36275] training loss: 0.010\n",
      "\n",
      "[Clustering Result]: ACC = 92.40, NMI = 84.34, ARI = 84.14\n",
      "Testing Accuracy : 92.400 %\n",
      "[iteration - 36686] training loss: 0.000\n",
      "\n",
      "[iteration - 37686] training loss: 0.007\n",
      "\n",
      "[Clustering Result]: ACC = 92.62, NMI = 84.78, ARI = 84.56\n",
      "Testing Accuracy : 92.620 %\n",
      "[iteration - 38097] training loss: 0.000\n",
      "\n",
      "[iteration - 39097] training loss: 0.005\n",
      "\n",
      "[Clustering Result]: ACC = 92.75, NMI = 84.74, ARI = 84.81\n",
      "Testing Accuracy : 92.750 %\n",
      "[iteration - 39508] training loss: 0.000\n",
      "\n",
      "[iteration - 40508] training loss: 0.009\n",
      "\n",
      "[Clustering Result]: ACC = 92.34, NMI = 84.23, ARI = 84.04\n",
      "Testing Accuracy : 92.340 %\n",
      "[iteration - 40919] training loss: 0.000\n",
      "\n",
      "[iteration - 41919] training loss: 0.007\n",
      "\n",
      "[Clustering Result]: ACC = 93.26, NMI = 85.76, ARI = 85.85\n",
      "Testing Accuracy : 93.260 %\n",
      "[iteration - 42330] training loss: 0.000\n",
      "\n",
      "[iteration - 43330] training loss: 0.005\n",
      "\n",
      "[Clustering Result]: ACC = 92.97, NMI = 85.21, ARI = 85.26\n",
      "Testing Accuracy : 92.970 %\n",
      "[iteration - 43741] training loss: 0.000\n",
      "\n",
      "[iteration - 44741] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 92.87, NMI = 85.34, ARI = 85.07\n",
      "Testing Accuracy : 92.870 %\n",
      "[iteration - 45152] training loss: 0.000\n",
      "\n",
      "[iteration - 46152] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.02, NMI = 85.35, ARI = 85.38\n",
      "Testing Accuracy : 93.020 %\n",
      "[iteration - 46563] training loss: 0.000\n",
      "\n",
      "[iteration - 47563] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.18, NMI = 85.60, ARI = 85.70\n",
      "Testing Accuracy : 93.180 %\n",
      "[iteration - 47974] training loss: 0.000\n",
      "\n",
      "[iteration - 48974] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.12, NMI = 85.49, ARI = 85.56\n",
      "Testing Accuracy : 93.120 %\n",
      "[iteration - 49385] training loss: 0.000\n",
      "\n",
      "[iteration - 50385] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.11, NMI = 85.49, ARI = 85.55\n",
      "Testing Accuracy : 93.110 %\n",
      "[iteration - 50796] training loss: 0.000\n",
      "\n",
      "[iteration - 51796] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.37, NMI = 85.96, ARI = 86.09\n",
      "Testing Accuracy : 93.370 %\n",
      "[iteration - 52207] training loss: 0.000\n",
      "\n",
      "[iteration - 53207] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.30, NMI = 85.89, ARI = 85.96\n",
      "Testing Accuracy : 93.300 %\n",
      "[iteration - 53618] training loss: 0.000\n",
      "\n",
      "[iteration - 54618] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.24, NMI = 85.72, ARI = 85.82\n",
      "Testing Accuracy : 93.240 %\n",
      "[iteration - 55029] training loss: 0.000\n",
      "\n",
      "[iteration - 56029] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.21, NMI = 85.63, ARI = 85.75\n",
      "Testing Accuracy : 93.210 %\n",
      "[iteration - 56440] training loss: 0.000\n",
      "\n",
      "[iteration - 57440] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.30, NMI = 85.82, ARI = 85.97\n",
      "Testing Accuracy : 93.300 %\n",
      "[iteration - 57851] training loss: 0.000\n",
      "\n",
      "[iteration - 58851] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.13, NMI = 85.58, ARI = 85.61\n",
      "Testing Accuracy : 93.130 %\n",
      "[iteration - 59262] training loss: 0.000\n",
      "\n",
      "[iteration - 60262] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.21, NMI = 85.67, ARI = 85.78\n",
      "Testing Accuracy : 93.210 %\n",
      "[iteration - 60673] training loss: 0.000\n",
      "\n",
      "[iteration - 61673] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.22, NMI = 85.68, ARI = 85.79\n",
      "Testing Accuracy : 93.220 %\n",
      "[iteration - 62084] training loss: 0.000\n",
      "\n",
      "[iteration - 63084] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.19, NMI = 85.66, ARI = 85.74\n",
      "Testing Accuracy : 93.190 %\n",
      "[iteration - 63495] training loss: 0.000\n",
      "\n",
      "[iteration - 64495] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.17, NMI = 85.59, ARI = 85.68\n",
      "Testing Accuracy : 93.170 %\n",
      "[iteration - 64906] training loss: 0.000\n",
      "\n",
      "[iteration - 65906] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.21, NMI = 85.64, ARI = 85.76\n",
      "Testing Accuracy : 93.210 %\n",
      "[iteration - 66317] training loss: 0.000\n",
      "\n",
      "[iteration - 67317] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.46, NMI = 86.13, ARI = 86.26\n",
      "Testing Accuracy : 93.460 %\n",
      "[iteration - 67728] training loss: 0.000\n",
      "\n",
      "[iteration - 68728] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.16, NMI = 85.58, ARI = 85.68\n",
      "Testing Accuracy : 93.160 %\n",
      "[iteration - 69139] training loss: 0.000\n",
      "\n",
      "[iteration - 70139] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.08, NMI = 85.45, ARI = 85.51\n",
      "Testing Accuracy : 93.080 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "\n",
    "# 定义数据预处理操作\n",
    "myTransforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# 加载训练数据集\n",
    "#train_dataset = torchvision.datasets.CIFAR10(root='./data/', train=True, download=True, transform=myTransforms)\n",
    "# 使用DataLoader加载训练数据，设置合适的batch_size、shuffle以及利用多进程加速数据加载（num_workers设为4，可根据实际调整）\n",
    "#train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "\n",
    "# 加载测试数据集\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./', train=False, download=True, transform=myTransforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "# 定义模型，加载预训练的ResNet50模型，并替换最后一层全连接层以适应CIFAR10的10分类任务\n",
    "myModel = torchvision.models.resnet50(pretrained=True)\n",
    "inchannel = myModel.fc.in_features\n",
    "myModel.fc = nn.Linear(inchannel, 10)\n",
    "\n",
    "# 将模型移动到GPU（如果可用）进行加速\n",
    "myDevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "myModel = myModel.to(myDevice)\n",
    "\n",
    "# 定义学习率、优化器和损失函数\n",
    "learning_rate = 0.001\n",
    "myOptimzier = optim.SGD(myModel.parameters(), lr=learning_rate, momentum=0.9)\n",
    "myLoss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for _epoch in range(50):\n",
    "    training_loss = 0.0\n",
    "    for _step, input_data in enumerate(train_loader):\n",
    "        image, label = input_data[0].to(myDevice), input_data[1].to(myDevice)\n",
    "        image = image.float()\n",
    "        predict_label = myModel(image)\n",
    "        predict_label = predict_label.float()\n",
    "        label = label.long()\n",
    "        loss = myLoss(predict_label, label)\n",
    "\n",
    "        # 将当前批次的损失添加到TensorBoard中记录\n",
    "        \n",
    "        # 优化器梯度清零，使用更高效的方式（set_to_none=True，需PyTorch 1.7及以上版本支持）\n",
    "        myOptimzier.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        myOptimzier.step()\n",
    "\n",
    "        # 累加当前批次的损失（使用更简洁的方式）\n",
    "        training_loss += loss.item()\n",
    "\n",
    "        # 每100个step打印一次训练损失，减少过多的打印输出\n",
    "        if _step % 1000 == 0:\n",
    "            print('[iteration - %3d] training loss: %.3f' % (_epoch * len(train_loader) + _step, training_loss / 1000))\n",
    "            training_loss = 0.0\n",
    "            print()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # 将模型设置为评估模式，关闭一些在训练时才需要的操作（如Dropout等）\n",
    "    LABEL_TEST=[]\n",
    "    LABEL_Prob=[]\n",
    "    LABEL_TRUE=[]\n",
    "    myModel.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(myDevice)\n",
    "            labels = labels.to(myDevice)\n",
    "            outputs = myModel(images)\n",
    "            LABEL_Prob.append(outputs.data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            LABEL_TEST.append(predicted.cpu().numpy())\n",
    "            LABEL_TRUE.append(labels.cpu().numpy())\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    LABEL_TEST= np.concatenate(LABEL_TEST, axis=0)\n",
    "    LABEL_TRUE= np.concatenate(LABEL_TRUE, axis=0)\n",
    "    cluster_metric(LABEL_TRUE, LABEL_TEST)\n",
    "    print('Testing Accuracy : %.3f %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc228f44-7dc6-4643-bb62-b7f3cf40a91e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2eaa4388-bdd6-4910-a7e9-5be15ecfd06c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #保存模型方便复现\n",
    "# torch.save(myModel, 'CIFAR10-myModel.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9af0a8-3333-43eb-904c-b79b58e65c20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae2c5af4-7bf1-4207-971f-9a459b3f811e",
   "metadata": {},
   "source": [
    "### Pseudo label Generation of Stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c041f2b6-e058-4052-9518-8abbd0d7d718",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform K-means clustering...\n",
      "K-means clustering done.\n",
      "[Clustering Result]: ACC = 90.67, NMI = 81.54, ARI = 80.77\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import faiss\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from eval_utils import cluster_metric\n",
    "\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "def kmeans(X, cluster_num):\n",
    "    print(\"Perform K-means clustering...\")\n",
    "    d = X.shape[1]\n",
    "    kmeans = faiss.Kmeans(d, cluster_num, gpu=True, spherical=True, niter=300, nredo=20)\n",
    "    X = X.astype(np.float32)\n",
    "    kmeans.train(X)\n",
    "    D, I = kmeans.index.search(X, 1)\n",
    "    I = I.reshape(-1)\n",
    "    print(\"K-means clustering done.\")\n",
    "    return I\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset = \"CIFAR-10\"  # 　[\"CIFAR-10\", \"CIFAR-20\", \"STL-10\", \"ImageNet-10\", \"ImageNet-Dogs\", \"DTD\", \"UCF101\", \"ImageNet\"]\n",
    "    tau = 0.005\n",
    "    if dataset == \"CIFAR-10\" or dataset == \"STL-10\" or dataset == \"ImageNet-10\":\n",
    "        cluster_num = 10\n",
    "    elif dataset == \"CIFAR-20\":\n",
    "        cluster_num = 20\n",
    "    elif dataset == \"ImageNet-Dogs\":\n",
    "        cluster_num = 15\n",
    "    elif dataset == \"DTD\":\n",
    "        cluster_num = 47\n",
    "    elif dataset == \"UCF101\":\n",
    "        cluster_num = 101\n",
    "    elif dataset == \"ImageNet\":\n",
    "        cluster_num = 1000\n",
    "    elif dataset == \"MNIST\":\n",
    "        cluster_num = 10\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    images_embedding_test = np.load(\"./\" + dataset + \"_image_embedding_test.npy\")\n",
    "    images_embedding_test = images_embedding_test / np.linalg.norm(\n",
    "        images_embedding_test, axis=1, keepdims=True\n",
    "    )\n",
    "    labels_test = np.loadtxt(\"./\" + dataset + \"_labels_test.txt\")\n",
    "\n",
    "    nouns_embedding = np.load(\"./\" + dataset + \"_filtered_nouns_embedding.npy\")\n",
    "    nouns_embedding = nouns_embedding / np.linalg.norm(\n",
    "        nouns_embedding, axis=1, keepdims=True\n",
    "    )\n",
    "\n",
    "    nouns_embedding = torch.from_numpy(nouns_embedding).cuda().half()\n",
    "    nouns_num = nouns_embedding.shape[0]\n",
    "    images_embedding_test = torch.from_numpy(images_embedding_test).cuda().half()\n",
    "    image_num_test = images_embedding_test.shape[0]\n",
    "\n",
    "    retrieval_embeddings = []\n",
    "    batch_size = 1024\n",
    "    for i in range(image_num_test // batch_size + 1):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        if end > image_num_test:\n",
    "            end = image_num_test\n",
    "            images_batch = images_embedding_test[start:end]\n",
    "        similarity = torch.matmul(images_embedding_test[start:end], nouns_embedding.T)\n",
    "        similarity = torch.softmax(similarity / tau, dim=1)\n",
    "        retrieval_embedding = (similarity @ nouns_embedding).cpu()\n",
    "        retrieval_embeddings.append(retrieval_embedding)\n",
    "    retrieval_embedding = torch.cat(retrieval_embeddings, dim=0).cuda().half()\n",
    "    retrieval_embedding = F.normalize(retrieval_embedding, dim=1).cpu().numpy()\n",
    "    images_embedding_test = images_embedding_test.cpu().numpy()\n",
    "\n",
    "    concat_embedding_test = np.concatenate([images_embedding_test, retrieval_embedding], axis=1)\n",
    "    preds_ = kmeans(concat_embedding_test, cluster_num)\n",
    "    cluster_metric(labels_test, preds_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e4c8162-7445-4710-a1c3-d44d4d8026b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LABEL_Prob_cpu = [tensor.cpu().numpy() for tensor in LABEL_Prob]\n",
    "LABEL_Prob_cpu = np.concatenate(LABEL_Prob_cpu)\n",
    "labels_res = np.argmax(LABEL_Prob_cpu, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "966f6f6e-d58d-4e3f-8a35-ba953b0a06fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最终得到的n*k的概率矩阵形状: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import torch\n",
    "d = concat_embedding_test.shape[1]\n",
    "k = cluster_num\n",
    "data = concat_embedding_test\n",
    "# 使用faiss进行Kmeans聚类，获取聚类中心\n",
    "clustering = faiss.Kmeans(d, k, spherical=True, niter=300, nredo=20)  # d是特征维度，k是聚类的类簇个数\n",
    "data=data.astype('float32')\n",
    "clustering.train(data)\n",
    "cluster_centers = clustering.centroids\n",
    "\n",
    "# 计算每个样本与聚类中心的余弦相似度\n",
    "def cosine_similarity(x, y):\n",
    "    \"\"\"\n",
    "    计算两个向量之间的余弦相似度\n",
    "    \"\"\"\n",
    "    x = x / np.linalg.norm(x, axis=1, keepdims=True)\n",
    "    y = y / np.linalg.norm(y, axis=1, keepdims=True)\n",
    "    return np.dot(x, y.T)\n",
    "\n",
    "similarities = cosine_similarity(data, cluster_centers)\n",
    "\n",
    "# 对余弦相似度结果求softmax，得到n*k的概率矩阵（这里使用torch来实现softmax，也可以使用其他库实现）\n",
    "similarities_tensor = torch.from_numpy(similarities)\n",
    "prob_matrix = torch.nn.functional.softmax(similarities_tensor, dim=1).numpy()\n",
    "\n",
    "print(\"最终得到的n*k的概率矩阵形状:\", prob_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "338dd771-64e2-45cd-8d0b-0b87598c46eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_kc = np.argmax(prob_matrix, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a81d54c-a51d-42c5-843f-bfe3d96ec6f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "concat_embedding_test_pseudo = np.concatenate([LABEL_Prob_cpu,prob_matrix], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52a47dd3-d8f5-4c82-96a5-521f3c358c1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "labels_res = get_y_preds(labels_kc, labels_res, cluster_num)\n",
    "mask_labels=(labels_kc==labels_res)\n",
    "# 假设prob_matrix和prob_matrix2是已经存在的形状为(n,)的类别索引矩阵\n",
    "labels_kc=labels_kc.astype(int)\n",
    "labels_res=labels_res.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c9bb1c9-07a2-436a-abbf-5530c4f01440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clustering Result]: ACC = 95.60, NMI = 90.42, ARI = 90.80\n"
     ]
    }
   ],
   "source": [
    "cluster_metric(labels_test[mask_labels], labels_res[mask_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d3b109d-c339-4c99-af75-d19212cd70c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9275"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_test[mask_labels])/len(labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c313b8-8154-4aff-af8d-4ea85011d036",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Stage 2: ResNet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca0e6c5f-da70-486d-885b-7b04f21eb47c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pseudo_labels=labels_res[mask_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb80129f-f727-4041-8c73-344160e51a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "训练数据加载器train_loader已创建成功！\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "# 定义数据变换（这里假设myTransforms已经在别处定义好了，你可以根据实际需求调整变换方式）\n",
    "\n",
    "pseudo_labels = torch.tensor(pseudo_labels)  # 假设是10分类任务，生成对应长度的伪标签\n",
    "\n",
    "# 之前定义的原始数据预处理操作（保持不变）\n",
    "myTransforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# 加载STL10训练数据集\n",
    "train_dataset =  torchvision.datasets.CIFAR10(root='./', train=False, download=True, transform=myTransforms)\n",
    "\n",
    "mask_list = [mask_labels]\n",
    "\n",
    "# 用于存储从train_dataset中根据掩码提取出来的数据和对应的伪标签\n",
    "subset_images = []\n",
    "\n",
    "# 依次根据掩码从train_dataset中提取数据并合并\n",
    "for mask in mask_list:\n",
    "    # 将掩码转换为布尔索引（如果不是布尔类型的话，需要进行相应转换）\n",
    "    if not isinstance(mask, np.ndarray):\n",
    "        mask = np.array(mask).astype(bool)\n",
    "    # 根据布尔索引从train_dataset中获取图像数据\n",
    "    subset_images.extend([train_dataset[i][0] for i in np.where(mask)[0]])\n",
    "    # 这里假设伪标签的获取方式是和图像数据对应的，你可以根据实际情况调整获取逻辑\n",
    "\n",
    "# 将合并后的数据和标签转换为Tensor类型\n",
    "subset_images = torch.stack(subset_images)\n",
    "\n",
    "# 创建自定义的Dataset，将合并后的数据和标签组合在一起\n",
    "combined_dataset = TensorDataset(subset_images, pseudo_labels)\n",
    "\n",
    "# 创建DataLoader，设置合适的参数，比如批量大小（batch_size）、是否打乱数据（shuffle）等\n",
    "batch_size = 32  # 可根据实际需求调整批量大小\n",
    "train_loader = DataLoader(combined_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "print(\"训练数据加载器train_loader已创建成功！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3797253e-533f-431c-a8df-2f56f61a0176",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "[iteration -   0] training loss: 0.002\n",
      "\n",
      "[Clustering Result]: ACC = 90.80, NMI = 81.74, ARI = 80.90\n",
      "Testing Accuracy : 1.770 %\n",
      "[iteration - 290] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 89.16, NMI = 79.82, ARI = 77.83\n",
      "Testing Accuracy : 1.370 %\n",
      "[iteration - 580] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 89.80, NMI = 81.06, ARI = 79.24\n",
      "Testing Accuracy : 2.430 %\n",
      "[iteration - 870] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 92.37, NMI = 84.86, ARI = 84.24\n",
      "Testing Accuracy : 1.550 %\n",
      "[iteration - 1160] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 92.14, NMI = 84.30, ARI = 83.56\n",
      "Testing Accuracy : 1.200 %\n",
      "[iteration - 1450] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 89.10, NMI = 80.94, ARI = 78.88\n",
      "Testing Accuracy : 1.700 %\n",
      "[iteration - 1740] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 91.84, NMI = 83.70, ARI = 83.07\n",
      "Testing Accuracy : 0.830 %\n",
      "[iteration - 2030] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.36, NMI = 85.90, ARI = 86.03\n",
      "Testing Accuracy : 1.140 %\n",
      "[iteration - 2320] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.16, NMI = 85.64, ARI = 85.65\n",
      "Testing Accuracy : 0.950 %\n",
      "[iteration - 2610] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.09, NMI = 85.55, ARI = 85.46\n",
      "Testing Accuracy : 0.950 %\n",
      "[iteration - 2900] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.87, NMI = 86.83, ARI = 87.03\n",
      "Testing Accuracy : 1.060 %\n",
      "[iteration - 3190] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.75, NMI = 86.72, ARI = 86.83\n",
      "Testing Accuracy : 0.960 %\n",
      "[iteration - 3480] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 90.90, NMI = 82.03, ARI = 81.21\n",
      "Testing Accuracy : 1.000 %\n",
      "[iteration - 3770] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 92.34, NMI = 84.61, ARI = 84.03\n",
      "Testing Accuracy : 1.130 %\n",
      "[iteration - 4060] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 91.63, NMI = 83.56, ARI = 82.38\n",
      "Testing Accuracy : 1.430 %\n",
      "[iteration - 4350] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 92.57, NMI = 84.48, ARI = 84.34\n",
      "Testing Accuracy : 0.970 %\n",
      "[iteration - 4640] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 92.46, NMI = 84.33, ARI = 84.18\n",
      "Testing Accuracy : 0.940 %\n",
      "[iteration - 4930] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.91, NMI = 87.06, ARI = 87.13\n",
      "Testing Accuracy : 0.950 %\n",
      "[iteration - 5220] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.84, NMI = 86.86, ARI = 87.01\n",
      "Testing Accuracy : 1.050 %\n",
      "[iteration - 5510] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.89, NMI = 87.00, ARI = 87.13\n",
      "Testing Accuracy : 1.050 %\n",
      "[iteration - 5800] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.76, NMI = 86.78, ARI = 86.87\n",
      "Testing Accuracy : 1.140 %\n",
      "[iteration - 6090] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.89, NMI = 86.96, ARI = 87.11\n",
      "Testing Accuracy : 1.060 %\n",
      "[iteration - 6380] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.94, NMI = 87.07, ARI = 87.22\n",
      "Testing Accuracy : 1.040 %\n",
      "[iteration - 6670] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.85, NMI = 86.88, ARI = 87.03\n",
      "Testing Accuracy : 1.060 %\n",
      "[iteration - 6960] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.77, NMI = 86.76, ARI = 86.88\n",
      "Testing Accuracy : 1.060 %\n",
      "[iteration - 7250] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.90, NMI = 87.02, ARI = 87.15\n",
      "Testing Accuracy : 1.050 %\n",
      "[iteration - 7540] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.88, NMI = 87.07, ARI = 87.10\n",
      "Testing Accuracy : 1.090 %\n",
      "[iteration - 7830] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.84, NMI = 86.90, ARI = 87.02\n",
      "Testing Accuracy : 1.110 %\n",
      "[iteration - 8120] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.95, NMI = 87.09, ARI = 87.24\n",
      "Testing Accuracy : 1.080 %\n",
      "[iteration - 8410] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.96, NMI = 87.11, ARI = 87.24\n",
      "Testing Accuracy : 1.090 %\n",
      "[iteration - 8700] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.92, NMI = 87.07, ARI = 87.18\n",
      "Testing Accuracy : 0.990 %\n",
      "[iteration - 8990] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.91, NMI = 87.09, ARI = 87.15\n",
      "Testing Accuracy : 1.080 %\n",
      "[iteration - 9280] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.84, NMI = 86.93, ARI = 87.02\n",
      "Testing Accuracy : 1.050 %\n",
      "[iteration - 9570] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.87, NMI = 86.99, ARI = 87.07\n",
      "Testing Accuracy : 1.120 %\n",
      "[iteration - 9860] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.76, NMI = 86.69, ARI = 86.85\n",
      "Testing Accuracy : 1.080 %\n",
      "[iteration - 10150] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.94, NMI = 87.13, ARI = 87.22\n",
      "Testing Accuracy : 1.090 %\n",
      "[iteration - 10440] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.94, NMI = 87.16, ARI = 87.23\n",
      "Testing Accuracy : 1.080 %\n",
      "[iteration - 10730] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.00, NMI = 87.26, ARI = 87.33\n",
      "Testing Accuracy : 1.130 %\n",
      "[iteration - 11020] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.94, NMI = 87.13, ARI = 87.24\n",
      "Testing Accuracy : 1.070 %\n",
      "[iteration - 11310] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.86, NMI = 86.95, ARI = 87.06\n",
      "Testing Accuracy : 1.060 %\n",
      "[iteration - 11600] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.81, NMI = 86.82, ARI = 86.96\n",
      "Testing Accuracy : 1.030 %\n",
      "[iteration - 11890] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.96, NMI = 87.19, ARI = 87.26\n",
      "Testing Accuracy : 1.090 %\n",
      "[iteration - 12180] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.97, NMI = 87.15, ARI = 87.27\n",
      "Testing Accuracy : 1.130 %\n",
      "[iteration - 12470] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.87, NMI = 86.99, ARI = 87.07\n",
      "Testing Accuracy : 1.050 %\n",
      "[iteration - 12760] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.78, NMI = 86.76, ARI = 86.89\n",
      "Testing Accuracy : 1.080 %\n",
      "[iteration - 13050] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.76, NMI = 86.86, ARI = 86.87\n",
      "Testing Accuracy : 1.080 %\n",
      "[iteration - 13340] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.88, NMI = 87.01, ARI = 87.12\n",
      "Testing Accuracy : 1.020 %\n",
      "[iteration - 13630] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.00, NMI = 87.26, ARI = 87.36\n",
      "Testing Accuracy : 1.070 %\n",
      "[iteration - 13920] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.96, NMI = 87.18, ARI = 87.26\n",
      "Testing Accuracy : 1.130 %\n",
      "[iteration - 14210] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.99, NMI = 87.15, ARI = 87.31\n",
      "Testing Accuracy : 1.080 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "\n",
    "# 定义数据预处理操作\n",
    "myTransforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# 加载训练数据集\n",
    "#train_dataset = torchvision.datasets.CIFAR10(root='./data/', train=True, download=True, transform=myTransforms)\n",
    "# 使用DataLoader加载训练数据，设置合适的batch_size、shuffle以及利用多进程加速数据加载（num_workers设为4，可根据实际调整）\n",
    "#train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "\n",
    "# 加载测试数据集\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./', train=False, download=True, transform=myTransforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "# 定义模型，加载预训练的ResNet50模型，并替换最后一层全连接层以适应CIFAR10的10分类任务\n",
    "myModel = torchvision.models.resnet50(pretrained=True)\n",
    "inchannel = myModel.fc.in_features\n",
    "myModel.fc = nn.Linear(inchannel, 10)\n",
    "\n",
    "# 将模型移动到GPU（如果可用）进行加速\n",
    "myDevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "myModel = myModel.to(myDevice)\n",
    "\n",
    "# 定义学习率、优化器和损失函数\n",
    "learning_rate = 0.001\n",
    "myOptimzier = optim.SGD(myModel.parameters(), lr=learning_rate, momentum=0.9)\n",
    "myLoss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for _epoch in range(50):\n",
    "    training_loss = 0.0\n",
    "    for _step, input_data in enumerate(train_loader):\n",
    "        image, label = input_data[0].to(myDevice), input_data[1].to(myDevice)\n",
    "        image = image.float()\n",
    "        predict_label = myModel(image)\n",
    "        predict_label = predict_label.float()\n",
    "        label = label.long()\n",
    "        loss = myLoss(predict_label, label)\n",
    "\n",
    "        # 将当前批次的损失添加到TensorBoard中记录\n",
    "        \n",
    "        # 优化器梯度清零，使用更高效的方式（set_to_none=True，需PyTorch 1.7及以上版本支持）\n",
    "        myOptimzier.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        myOptimzier.step()\n",
    "\n",
    "        # 累加当前批次的损失（使用更简洁的方式）\n",
    "        training_loss += loss.item()\n",
    "\n",
    "        # 每100个step打印一次训练损失，减少过多的打印输出\n",
    "        if _step % 1000 == 0:\n",
    "            print('[iteration - %3d] training loss: %.3f' % (_epoch * len(train_loader) + _step, training_loss / 1000))\n",
    "            training_loss = 0.0\n",
    "            print()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # 将模型设置为评估模式，关闭一些在训练时才需要的操作（如Dropout等）\n",
    "    LABEL_TEST=[]\n",
    "    LABEL_Prob=[]\n",
    "    LABEL_TRUE=[]\n",
    "    myModel.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(myDevice)\n",
    "            labels = labels.to(myDevice)\n",
    "            outputs = myModel(images)\n",
    "            LABEL_Prob.append(outputs.data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            LABEL_TEST.append(predicted.cpu().numpy())\n",
    "            LABEL_TRUE.append(labels.cpu().numpy())\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    LABEL_TEST= np.concatenate(LABEL_TEST, axis=0)\n",
    "    LABEL_TRUE= np.concatenate(LABEL_TRUE, axis=0)\n",
    "    cluster_metric(LABEL_TRUE, LABEL_TEST)\n",
    "    print('Testing Accuracy : %.3f %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b3ed5e-858d-431b-8aad-b216837fc69f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a1e5d2b-d25d-4a10-ae06-d83fe040ac56",
   "metadata": {},
   "source": [
    "### Pseudo label Generation of Stage 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23195ddf-5d7a-490a-be7d-27ce2052bbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_Prob_cpu1 = [tensor.cpu().numpy() for tensor in LABEL_Prob]\n",
    "LABEL_Prob_cpu1 = np.concatenate(LABEL_Prob_cpu1)\n",
    "labels_res1 = np.argmax(LABEL_Prob_cpu1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34eae9e9-ff5e-40a6-9397-0a2e337cfb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_embedding_test_pseudo = np.concatenate([LABEL_Prob_cpu,LABEL_Prob_cpu1,prob_matrix], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7da91a0c-f823-454b-9381-5f6544b733e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "labels_res=labels_res.astype(int)\n",
    "labels_kc=labels_kc.astype(int)\n",
    "labels_res = get_y_preds(labels_res1, labels_res, cluster_num)\n",
    "labels_kc = get_y_preds(labels_res1, labels_kc, cluster_num)\n",
    "mask_labels=(labels_res1==labels_res)|((labels_res1==labels_kc)&(labels_res==labels_kc))\n",
    "# 假设prob_matrix和prob_matrix2是已经存在的形状为(n,)的类别索引矩阵\n",
    "labels_res1=labels_res1.astype(int)\n",
    "labels_res=labels_res.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80c19aa5-baec-4b9f-a716-bbfdb8cc6a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clustering Result]: ACC = 95.49, NMI = 90.08, ARI = 90.43\n"
     ]
    }
   ],
   "source": [
    "cluster_metric(labels_test[mask_labels], labels_res1[mask_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "451dbf75-23c3-4a71-93e2-58c9a33780f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9672"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_test[mask_labels])/len(labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15bc576-8b59-4bf8-a66c-38ba80a567ef",
   "metadata": {},
   "source": [
    "### Stage 3: ResNet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4ad4db5-5d01-4587-a9cf-4ff1908bec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_labels=labels_res1[mask_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3da9aaa1-1bf2-4181-98cf-83f943eb8597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "训练数据加载器train_loader已创建成功！\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "# 定义数据变换（这里假设myTransforms已经在别处定义好了，你可以根据实际需求调整变换方式）\n",
    "\n",
    "pseudo_labels = torch.tensor(pseudo_labels)  # 假设是10分类任务，生成对应长度的伪标签\n",
    "\n",
    "# 之前定义的原始数据预处理操作（保持不变）\n",
    "myTransforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# 加载STL10训练数据集\n",
    "train_dataset =  torchvision.datasets.CIFAR10(root='./', train=False, download=True, transform=myTransforms)\n",
    "\n",
    "mask_list = [mask_labels]\n",
    "\n",
    "# 用于存储从train_dataset中根据掩码提取出来的数据和对应的伪标签\n",
    "subset_images = []\n",
    "\n",
    "# 依次根据掩码从train_dataset中提取数据并合并\n",
    "for mask in mask_list:\n",
    "    # 将掩码转换为布尔索引（如果不是布尔类型的话，需要进行相应转换）\n",
    "    if not isinstance(mask, np.ndarray):\n",
    "        mask = np.array(mask).astype(bool)\n",
    "    # 根据布尔索引从train_dataset中获取图像数据\n",
    "    subset_images.extend([train_dataset[i][0] for i in np.where(mask)[0]])\n",
    "    # 这里假设伪标签的获取方式是和图像数据对应的，你可以根据实际情况调整获取逻辑\n",
    "\n",
    "# 将合并后的数据和标签转换为Tensor类型\n",
    "subset_images = torch.stack(subset_images)\n",
    "\n",
    "# 创建自定义的Dataset，将合并后的数据和标签组合在一起\n",
    "combined_dataset = TensorDataset(subset_images, pseudo_labels)\n",
    "\n",
    "# 创建DataLoader，设置合适的参数，比如批量大小（batch_size）、是否打乱数据（shuffle）等\n",
    "batch_size = 32  # 可根据实际需求调整批量大小\n",
    "train_loader = DataLoader(combined_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "print(\"训练数据加载器train_loader已创建成功！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "570fe455-b28f-4dfd-ade0-7ada5b8045f7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "[iteration -   0] training loss: 0.002\n",
      "\n",
      "[Clustering Result]: ACC = 91.36, NMI = 82.48, ARI = 82.02\n",
      "Testing Accuracy : 1.430 %\n",
      "[iteration - 303] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 91.32, NMI = 82.54, ARI = 81.88\n",
      "Testing Accuracy : 0.700 %\n",
      "[iteration - 606] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 92.15, NMI = 84.20, ARI = 83.67\n",
      "Testing Accuracy : 1.350 %\n",
      "[iteration - 909] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 90.75, NMI = 81.33, ARI = 80.92\n",
      "Testing Accuracy : 1.020 %\n",
      "[iteration - 1212] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 90.99, NMI = 82.80, ARI = 81.46\n",
      "Testing Accuracy : 1.170 %\n",
      "[iteration - 1515] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 92.81, NMI = 85.16, ARI = 84.93\n",
      "Testing Accuracy : 1.170 %\n",
      "[iteration - 1818] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 92.51, NMI = 84.72, ARI = 84.22\n",
      "Testing Accuracy : 1.090 %\n",
      "[iteration - 2121] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 92.57, NMI = 84.71, ARI = 84.43\n",
      "Testing Accuracy : 1.180 %\n",
      "[iteration - 2424] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.26, NMI = 85.95, ARI = 85.80\n",
      "Testing Accuracy : 1.120 %\n",
      "[iteration - 2727] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.27, NMI = 86.12, ARI = 85.80\n",
      "Testing Accuracy : 0.900 %\n",
      "[iteration - 3030] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.49, NMI = 86.06, ARI = 86.27\n",
      "Testing Accuracy : 0.860 %\n",
      "[iteration - 3333] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.37, NMI = 86.32, ARI = 86.02\n",
      "Testing Accuracy : 1.280 %\n",
      "[iteration - 3636] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.12, NMI = 87.30, ARI = 87.57\n",
      "Testing Accuracy : 0.920 %\n",
      "[iteration - 3939] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.11, NMI = 87.43, ARI = 87.54\n",
      "Testing Accuracy : 1.030 %\n",
      "[iteration - 4242] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.21, NMI = 87.60, ARI = 87.76\n",
      "Testing Accuracy : 1.000 %\n",
      "[iteration - 4545] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.01, NMI = 87.10, ARI = 87.34\n",
      "Testing Accuracy : 1.030 %\n",
      "[iteration - 4848] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.18, NMI = 87.46, ARI = 87.69\n",
      "Testing Accuracy : 0.990 %\n",
      "[iteration - 5151] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.28, NMI = 87.51, ARI = 87.88\n",
      "Testing Accuracy : 0.980 %\n",
      "[iteration - 5454] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.22, NMI = 87.52, ARI = 87.78\n",
      "Testing Accuracy : 0.970 %\n",
      "[iteration - 5757] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.40, NMI = 87.87, ARI = 88.14\n",
      "Testing Accuracy : 0.940 %\n",
      "[iteration - 6060] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.01, NMI = 87.21, ARI = 87.36\n",
      "Testing Accuracy : 0.980 %\n",
      "[iteration - 6363] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.03, NMI = 87.14, ARI = 87.39\n",
      "Testing Accuracy : 1.030 %\n",
      "[iteration - 6666] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.13, NMI = 87.35, ARI = 87.59\n",
      "Testing Accuracy : 0.960 %\n",
      "[iteration - 6969] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.15, NMI = 87.39, ARI = 87.64\n",
      "Testing Accuracy : 1.060 %\n",
      "[iteration - 7272] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.18, NMI = 87.48, ARI = 87.70\n",
      "Testing Accuracy : 1.040 %\n",
      "[iteration - 7575] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.11, NMI = 87.31, ARI = 87.55\n",
      "Testing Accuracy : 1.050 %\n",
      "[iteration - 7878] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.07, NMI = 87.26, ARI = 87.47\n",
      "Testing Accuracy : 1.050 %\n",
      "[iteration - 8181] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.15, NMI = 87.44, ARI = 87.64\n",
      "Testing Accuracy : 1.060 %\n",
      "[iteration - 8484] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.14, NMI = 87.38, ARI = 87.62\n",
      "Testing Accuracy : 1.060 %\n",
      "[iteration - 8787] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.11, NMI = 87.35, ARI = 87.56\n",
      "Testing Accuracy : 1.000 %\n",
      "[iteration - 9090] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.20, NMI = 87.52, ARI = 87.74\n",
      "Testing Accuracy : 0.980 %\n",
      "[iteration - 9393] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.01, NMI = 87.16, ARI = 87.35\n",
      "Testing Accuracy : 1.070 %\n",
      "[iteration - 9696] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.16, NMI = 87.38, ARI = 87.66\n",
      "Testing Accuracy : 1.020 %\n",
      "[iteration - 9999] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.07, NMI = 87.24, ARI = 87.47\n",
      "Testing Accuracy : 1.070 %\n",
      "[iteration - 10302] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.96, NMI = 87.06, ARI = 87.26\n",
      "Testing Accuracy : 1.060 %\n",
      "[iteration - 10605] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.11, NMI = 87.30, ARI = 87.55\n",
      "Testing Accuracy : 1.010 %\n",
      "[iteration - 10908] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.13, NMI = 87.38, ARI = 87.60\n",
      "Testing Accuracy : 1.040 %\n",
      "[iteration - 11211] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.04, NMI = 87.21, ARI = 87.42\n",
      "Testing Accuracy : 1.020 %\n",
      "[iteration - 11514] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.18, NMI = 87.44, ARI = 87.70\n",
      "Testing Accuracy : 1.030 %\n",
      "[iteration - 11817] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.09, NMI = 87.31, ARI = 87.52\n",
      "Testing Accuracy : 0.990 %\n",
      "[iteration - 12120] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.97, NMI = 87.04, ARI = 87.27\n",
      "Testing Accuracy : 1.050 %\n",
      "[iteration - 12423] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.24, NMI = 87.59, ARI = 87.83\n",
      "Testing Accuracy : 0.950 %\n",
      "[iteration - 12726] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.09, NMI = 87.28, ARI = 87.53\n",
      "Testing Accuracy : 1.000 %\n",
      "[iteration - 13029] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 93.97, NMI = 87.11, ARI = 87.29\n",
      "Testing Accuracy : 1.020 %\n",
      "[iteration - 13332] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.16, NMI = 87.45, ARI = 87.66\n",
      "Testing Accuracy : 0.990 %\n",
      "[iteration - 13635] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.17, NMI = 87.46, ARI = 87.68\n",
      "Testing Accuracy : 1.030 %\n",
      "[iteration - 13938] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.14, NMI = 87.36, ARI = 87.61\n",
      "Testing Accuracy : 1.050 %\n",
      "[iteration - 14241] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.11, NMI = 87.43, ARI = 87.58\n",
      "Testing Accuracy : 1.000 %\n",
      "[iteration - 14544] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.21, NMI = 87.56, ARI = 87.78\n",
      "Testing Accuracy : 1.010 %\n",
      "[iteration - 14847] training loss: 0.000\n",
      "\n",
      "[Clustering Result]: ACC = 94.17, NMI = 87.45, ARI = 87.69\n",
      "Testing Accuracy : 0.960 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "\n",
    "# 定义数据预处理操作\n",
    "myTransforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# 加载训练数据集\n",
    "#train_dataset = torchvision.datasets.CIFAR10(root='./data/', train=True, download=True, transform=myTransforms)\n",
    "# 使用DataLoader加载训练数据，设置合适的batch_size、shuffle以及利用多进程加速数据加载（num_workers设为4，可根据实际调整）\n",
    "#train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "\n",
    "# 加载测试数据集\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./', train=False, download=True, transform=myTransforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "# 定义模型，加载预训练的ResNet50模型，并替换最后一层全连接层以适应CIFAR10的10分类任务\n",
    "myModel = torchvision.models.resnet50(pretrained=True)\n",
    "inchannel = myModel.fc.in_features\n",
    "myModel.fc = nn.Linear(inchannel, 10)\n",
    "\n",
    "# 将模型移动到GPU（如果可用）进行加速\n",
    "myDevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "myModel = myModel.to(myDevice)\n",
    "\n",
    "# 定义学习率、优化器和损失函数\n",
    "learning_rate = 0.001\n",
    "myOptimzier = optim.SGD(myModel.parameters(), lr=learning_rate, momentum=0.9)\n",
    "myLoss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for _epoch in range(50):\n",
    "    training_loss = 0.0\n",
    "    for _step, input_data in enumerate(train_loader):\n",
    "        image, label = input_data[0].to(myDevice), input_data[1].to(myDevice)\n",
    "        image = image.float()\n",
    "        predict_label = myModel(image)\n",
    "        predict_label = predict_label.float()\n",
    "        label = label.long()\n",
    "        loss = myLoss(predict_label, label)\n",
    "\n",
    "        # 将当前批次的损失添加到TensorBoard中记录\n",
    "        \n",
    "        # 优化器梯度清零，使用更高效的方式（set_to_none=True，需PyTorch 1.7及以上版本支持）\n",
    "        myOptimzier.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        myOptimzier.step()\n",
    "\n",
    "        # 累加当前批次的损失（使用更简洁的方式）\n",
    "        training_loss += loss.item()\n",
    "\n",
    "        # 每100个step打印一次训练损失，减少过多的打印输出\n",
    "        if _step % 1000 == 0:\n",
    "            print('[iteration - %3d] training loss: %.3f' % (_epoch * len(train_loader) + _step, training_loss / 1000))\n",
    "            training_loss = 0.0\n",
    "            print()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # 将模型设置为评估模式，关闭一些在训练时才需要的操作（如Dropout等）\n",
    "    LABEL_TEST=[]\n",
    "    LABEL_Prob=[]\n",
    "    LABEL_TRUE=[]\n",
    "    myModel.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(myDevice)\n",
    "            labels = labels.to(myDevice)\n",
    "            outputs = myModel(images)\n",
    "            LABEL_Prob.append(outputs.data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            LABEL_TEST.append(predicted.cpu().numpy())\n",
    "            LABEL_TRUE.append(labels.cpu().numpy())\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    LABEL_TEST= np.concatenate(LABEL_TEST, axis=0)\n",
    "    LABEL_TRUE= np.concatenate(LABEL_TRUE, axis=0)\n",
    "    cluster_metric(LABEL_TRUE, LABEL_TEST)\n",
    "    print('Testing Accuracy : %.3f %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb914aa7-b291-4daa-bb52-389dce29a518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "467c7c80-308a-4ad7-ad05-46e53d8234ed",
   "metadata": {},
   "source": [
    "### Final Clustering results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e441c02-bf90-413f-83c9-fe2539862a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_Prob_cpu2 = [tensor.cpu().numpy() for tensor in LABEL_Prob]\n",
    "LABEL_Prob_cpu2 = np.concatenate(LABEL_Prob_cpu2)\n",
    "labels_res2 = np.argmax(LABEL_Prob_cpu2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3abd2f2b-c0f1-4b0f-8eaa-763e7cbf32d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_embedding_test_pseudo = np.concatenate([LABEL_Prob_cpu1,LABEL_Prob_cpu2,LABEL_Prob_cpu,prob_matrix], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b875ad3-5fef-4466-8395-06b6e4838ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "labels_res=labels_res.astype(int)\n",
    "labels_kc=labels_kc.astype(int)\n",
    "labels_res1 = get_y_preds(labels_res2, labels_res1, cluster_num)\n",
    "labels_kc = get_y_preds(labels_res2, labels_kc, cluster_num)\n",
    "labels_res = get_y_preds(labels_res2, labels_res, cluster_num)\n",
    "mask_labels=(labels_res1==labels_res2) |(labels_res2==labels_res)|((labels_res2==labels_kc)&(labels_res1==labels_res))\n",
    "# 假设prob_matrix和prob_matrix2是已经存在的形状为(n,)的类别索引矩阵\n",
    "labels_res1=labels_res1.astype(int)\n",
    "labels_res=labels_res.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e3676e4b-1e42-4d01-a28d-66f13c59792f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clustering Result]: ACC = 94.54, NMI = 88.19, ARI = 88.46\n"
     ]
    }
   ],
   "source": [
    "cluster_metric(labels_test[mask_labels], labels_res1[mask_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b178499-5444-443c-9f5e-6a68d0a39a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9901"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_test[mask_labels])/len(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "153cf821-13e1-4365-9a1b-511312fb4f06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# np.save(\"./\" + dataset + \"_mask_labels.npy\",mask_labels)\n",
    "# np.save(\"./\" + dataset + \"_concat_embedding_test_pseudo.npy\",concat_embedding_test_pseudo)\n",
    "# np.save(\"./\" + dataset + \"_labels_res.npy\",labels_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0010e576-f556-4c96-9671-ec3466a6650b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform K-means clustering...\n",
      "K-means clustering done.\n",
      "[Clustering Result]: ACC = 94.33, NMI = 87.78, ARI = 88.01\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "def kmeans(X, cluster_num):\n",
    "    print(\"Perform K-means clustering...\")\n",
    "    d = X.shape[1]\n",
    "    kmeans = faiss.Kmeans(d, cluster_num, gpu=True, spherical=True, niter=300, nredo=20)\n",
    "    X = X.astype(np.float32)\n",
    "    kmeans.train(X)\n",
    "    D, I = kmeans.index.search(X, 1)\n",
    "    I = I.reshape(-1)\n",
    "    print(\"K-means clustering done.\")\n",
    "    return I\n",
    "cluster_num=10\n",
    "preds = kmeans(concat_embedding_test_pseudo, cluster_num)\n",
    "cluster_metric(labels_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9463a0-7d4f-43be-afc6-aa12c4cba373",
   "metadata": {},
   "source": [
    "### The reproduced results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f8e0e292-032b-4393-b338-66a757230a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= \"CIFAR-10\"\n",
    "mask_labels=np.load(\"./\" + dataset + \"_mask_labels.npy\")\n",
    "concat_embedding_test_pseudo=np.load(\"./\" + dataset + \"_concat_embedding_test_pseudo.npy\")\n",
    "labels_res=np.load(\"./\" + dataset + \"_labels_res.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "70a2ea0b-19c1-480e-b59c-ee9a7e74f79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform K-means clustering...\n",
      "K-means clustering done.\n",
      "[Clustering Result]: ACC = 94.27, NMI = 87.74, ARI = 87.91\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "def kmeans(X, cluster_num):\n",
    "    print(\"Perform K-means clustering...\")\n",
    "    d = X.shape[1]\n",
    "    kmeans = faiss.Kmeans(d, cluster_num, gpu=True, spherical=True, niter=300, nredo=20)\n",
    "    X = X.astype(np.float32)\n",
    "    kmeans.train(X)\n",
    "    D, I = kmeans.index.search(X, 1)\n",
    "    I = I.reshape(-1)\n",
    "    print(\"K-means clustering done.\")\n",
    "    return I\n",
    "cluster_num=10\n",
    "preds = kmeans(concat_embedding_test_pseudo, cluster_num)\n",
    "cluster_metric(labels_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60084266-0594-44b2-80b2-65fa27801bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216f4acb-5f94-4c36-8621-8867e7ca341f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
